<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;jiangzhiqi4551.github.io&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Pisces&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;}}</script><script src="/js/config.js"></script>
<meta property="og:type" content="website">
<meta property="og:title" content="Jiang&#39;s blog">
<meta property="og:url" content="https://jiangzhiqi4551.github.io/index.html">
<meta property="og:site_name" content="Jiang&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Master Jiang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://jiangzhiqi4551.github.io/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Jiang's blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Jiang's blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Master Jiang"
      src="/images/logo1.jpeg">
  <p class="site-author-name" itemprop="name">Master Jiang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">25</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">5</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Jiangzhiqi4551" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Jiangzhiqi4551" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:Jiangzhiqi4551@outlook.com" title="E-Mail → mailto:Jiangzhiqi4551@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Jiangzhiqi4551?spm=1000.2115.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Jiangzhiqi4551?spm&#x3D;1000.2115.3001.5343" rel="noopener" target="_blank"><i class="fas fa-blog fa-fw"></i>CSDN</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/29/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B003/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/29/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B003/" class="post-title-link" itemprop="url">数据仓库工具箱笔记 - 第三章</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-29 10:48:42" itemprop="dateCreated datePublished" datetime="2021-06-29T10:48:42+08:00">2021-06-29</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-10-09 18:38:43" itemprop="dateModified" datetime="2021-10-09T18:38:43+08:00">2021-10-09</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据仓库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="维度模型设计的四个步骤"><a href="#维度模型设计的四个步骤" class="headerlink" title="维度模型设计的四个步骤"></a>维度模型设计的四个步骤</h1>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2021/06/29/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B003/#more" rel="contents">
                阅读全文 &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/28/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B002/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/28/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B002/" class="post-title-link" itemprop="url">数据仓库工具箱笔记 - 第二章</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-28 10:58:40" itemprop="dateCreated datePublished" datetime="2021-06-28T10:58:40+08:00">2021-06-28</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-06-29 10:44:19" itemprop="dateModified" datetime="2021-06-29T10:44:19+08:00">2021-06-29</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据仓库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h1><h3 id="维度模型设计四步骤"><a href="#维度模型设计四步骤" class="headerlink" title="维度模型设计四步骤"></a>维度模型设计四步骤</h3><p>​        1、选择业务过程</p>
<p>​                每个业务过程对应数仓总线矩阵的一行。</p>
<p>​        2、确认粒度</p>
<p>​                粒度用于确定事实表中的行表示什么。</p>
<p>​        3、确认维度</p>
<p>​                维度描述业务过程事件所涉及的“谁、什么、何处、何时、为什么、如何”等背景。</p>
<p>​        4、确认事实</p>
<p>​                事实涉及来自业务过程事件的度量，基本以数值表示。</p>
<p>​                一个事实表中的每一行，都与按照事实表粒度描述的度量事件存在一对一的关系。</p>
<h1 id="事实表技术基础"><a href="#事实表技术基础" class="headerlink" title="事实表技术基础"></a>事实表技术基础</h1><h4 id="事实表结构"><a href="#事实表结构" class="headerlink" title="事实表结构"></a>事实表结构</h4><p>​        事实表行对应一个度量事件，事实表的设计完全依赖于物理活动，不受最终产出报表的影响。事实表还包含外键（用于维度关联）、可选的退化维度键、日期时间戳。</p>
<h4 id="可加、半可加、不可加事实"><a href="#可加、半可加、不可加事实" class="headerlink" title="可加、半可加、不可加事实"></a>可加、半可加、不可加事实</h4><p>​        可加性数字度量：可以按任意维度汇总</p>
<p>​        半可加性数字度量：可以对某些维度汇总（例如差额）</p>
<p>​        不可加性数字度量：完全不可加（例如比率）</p>
<h4 id="一致性事实"><a href="#一致性事实" class="headerlink" title="一致性事实"></a>一致性事实</h4><p>​        比较、计算不同事实表中的事实，必须保证事实的技术定义一致，如果一致，应该采用相同的命名。</p>
<h4 id="事务事实表"><a href="#事务事实表" class="headerlink" title="事务事实表"></a>事务事实表</h4><p>​        一行对应空间上或时间上某点的度量事件。</p>
<h4 id="周期快照事实表"><a href="#周期快照事实表" class="headerlink" title="周期快照事实表"></a>周期快照事实表</h4><p>​        一行汇总了发生在某个标准周期（一天、一周）内的多个度量事件。粒度是周期性的，不是个体的事务，表中通常包含许多事实。</p>
<h4 id="累积快照事实表"><a href="#累积快照事实表" class="headerlink" title="累积快照事实表"></a>累积快照事实表</h4><p>​        一行汇总了发生在过程开始到结束之间的、可预测的度量事件。</p>
<h4 id="聚集事实表"><a href="#聚集事实表" class="headerlink" title="聚集事实表"></a>聚集事实表</h4><p>​        对原子粒度事实数据表进行简单的上卷操作，目的是提高查询性能。</p>
<h4 id="合并事实表"><a href="#合并事实表" class="headerlink" title="合并事实表"></a>合并事实表</h4><p>​        将来自多个过程的，粒度相同的事实表合并为一个单一的事实表。</p>
<p>​        增加了ETL的处理负担，降低了BI应用的分析代价，适合经常需要共同分析的多过程度量（指标）。</p>
<h1 id="维度表技术基础"><a href="#维度表技术基础" class="headerlink" title="维度表技术基础"></a>维度表技术基础</h1><h4 id="退化维度"><a href="#退化维度" class="headerlink" title="退化维度"></a>退化维度</h4><p>​        事实表中存在着看起来像关联维度表的外键，但事实上没有维度表和维度关联，也就是说退化维度相关的数据都在事实表中。</p>
<h4 id="杂项维度"><a href="#杂项维度" class="headerlink" title="杂项维度"></a>杂项维度</h4><p>​        将多个不同维度合并到一起形成单个维度。</p>
<h4 id="支架维度"><a href="#支架维度" class="headerlink" title="支架维度"></a>支架维度</h4><p>​        维度包含对其他维度的引用，事实表关联维度表A，维度表A引用维度表B，B称为支架维度。</p>
<h4 id="一致性维度"><a href="#一致性维度" class="headerlink" title="一致性维度"></a>一致性维度</h4><p>​        不同维度表的属性具有相同的列名和领域内容时，称维度表具有一致性，利用一致性维度关联各个事实表，可以将来自不同事实表的信息合并到一张报表中。</p>
<h4 id="缩减维度"><a href="#缩减维度" class="headerlink" title="缩减维度"></a>缩减维度</h4><p>​        缩减维度也是一种一致性维度，由基本维度的列、行的子集构成。</p>
<h4 id="总线矩阵"><a href="#总线矩阵" class="headerlink" title="总线矩阵"></a>总线矩阵</h4><p>​        矩阵的行表示业务过程，列表示维度。矩阵中的点表示给定的维度和业务过程是否有联系。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/09/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B001/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/09/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E5%B7%A5%E5%85%B7%E7%AE%B1%E7%AC%94%E8%AE%B001/" class="post-title-link" itemprop="url">数据仓库工具箱笔记 - 第一章</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2021-06-09 20:06:32" itemprop="dateCreated datePublished" datetime="2021-06-09T20:06:32+08:00">2021-06-09</time>
    </span>
      <span class="post-meta-item">
        <span class="post-meta-item-icon">
          <i class="far fa-calendar-check"></i>
        </span>
        <span class="post-meta-item-text">更新于</span>
        <time title="修改时间：2021-06-28 10:53:17" itemprop="dateModified" datetime="2021-06-28T10:53:17+08:00">2021-06-28</time>
      </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据仓库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="第一章"><a href="#第一章" class="headerlink" title="第一章"></a>第一章</h1><h2 id="为什么使用维度建模不使用ER模型"><a href="#为什么使用维度建模不使用ER模型" class="headerlink" title="为什么使用维度建模不使用ER模型"></a>为什么使用维度建模不使用ER模型</h2><p>规范化的模型主要用于操作型过程中，因为对事物的更新和插入仅触及数据库单一的地方。</p>
<p>对BI查询来说，规范化的模型太复杂，用户难以理解和检索，复杂查询时将耗尽数据库的优化器性能，严重影响查询的性能，不能高性能检索。</p>
<h2 id="度建模的核心原则"><a href="#度建模的核心原则" class="headerlink" title="度建模的核心原则"></a>度建模的核心原则</h2><p>1、建立事实表时使用统一的细节级别（粒度），可以避免出现重复计算度量的问题。（事实表中每一行对应一个度量事件）</p>
<p>2、文本数据应尽量放在维表中，尽量不冗余到事实表。</p>
<h2 id="总线矩阵存在的意义"><a href="#总线矩阵存在的意义" class="headerlink" title="总线矩阵存在的意义"></a>总线矩阵存在的意义</h2><p>多数情况下，用户获得有限的数据源，并用于解决特定的问题，输出独立的、烟囱式的数据系统，其他人不能复用，也不能与组织的其他分析信息相关联。</p>
<p>采用总线矩阵可以为敏捷开发提供框架和主生产计划，提供可用的、公共的维度，保障数据一致性。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/%E5%9F%BA%E4%BA%8EGeohash%E5%AE%9E%E7%8E%B0%E6%A0%B9%E6%8D%AE%E7%BB%8F%E7%BA%AC%E5%BA%A6%E7%9A%84%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/%E5%9F%BA%E4%BA%8EGeohash%E5%AE%9E%E7%8E%B0%E6%A0%B9%E6%8D%AE%E7%BB%8F%E7%BA%AC%E5%BA%A6%E7%9A%84%E5%BF%AB%E9%80%9F%E5%AE%9A%E4%BD%8D/" class="post-title-link" itemprop="url">基于Geohash实现根据经纬度的快速定位</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:47:31 / 修改时间：18:49:12" itemprop="dateCreated datePublished" datetime="2021-06-08T18:47:31+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%99%E7%A8%8B/" itemprop="url" rel="index"><span itemprop="name">教程</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="背景介绍"><a href="#背景介绍" class="headerlink" title="背景介绍"></a>背景介绍</h2><p>在项目中，SDK会上报包含用户经纬度信息的一系列数据，我们需要根据经纬度信息定位出此条数据上报时用户所在的位置（包括国家、省、市、区），并和其他信息写入宽表中。</p>
<h4 id="旧方案"><a href="#旧方案" class="headerlink" title="旧方案"></a>旧方案</h4><p>旧方案中，主要使用GeoSpark对数据进行定位，考虑到同一个经纬度下会有多条数据，所以我们先对数据做分组，同一个用户同一个会话下相同经纬度的数据分为一组，从每组数据中抽取第一条生成一张临时表，再在临时表上调用GeoSpark算出district_id，city_id，province_id，country_id，之后将临时表与原表关联，用临时表的四个ID填充相同经纬度的其他数据的ID。<br>在测试过程中，我们发现有很小一部分数据只有district_id或city_id等细粒度数据，却没有与之相对的province_id、country_id等数据，这是老大所不能接受的（在哪个城市都知道了，国家你给我个null？？？ =。=），所以在计算四个ID之后，会有一个反推的步骤，即：判断是否有下层ID不为空上层ID却为空的情况，如果有，通过下层ID进行反推，得到上层ID，并填充。</p>
<p>中间还有一些其他的过滤排序逻辑不做具体介绍，最后当整个定位逻辑完成后，需要做6~7次的shuffle，我们发现其性能远低于预期，在我们每天将近40亿的数据量下，较大的拖慢了整个流程的运行速度，影响了数据产出，因此需要对这一部分进行优化。经过调研后，本菜鸡决定采用GeoHash的方式进行优化。</p>
<h2 id="什么是Geohash"><a href="#什么是Geohash" class="headerlink" title="什么是Geohash"></a>什么是Geohash</h2><p>简单介绍下GeoHash，我们可以用一个经纬度的点（例如点A： 37.788422,-122.391907 ）计算出一个GeoHash字符串（9q8yyzh），这个字符串代表一个矩形面，点A以及点A附近的点B（37.787933,-122.392887）虽然经纬度不同，但通过经纬度计算出的GeoHash字符串相同，也就是说AB两个点都在（9q8yyzh）这个面内。这样就将二维的经纬度坐标转换成了一维的字符串表示。</p>
<p>但A附近的多少点会跟A共享相同的字符串呢？也就是这个面的大小是怎么确定的呢？这就取决于GeoHash字符串的长度了，GeoHash的字符串长度越长，意味着这个面也就越小，会有更少的点跟A共享同样的GeoHash值。</p>
<p>具体GeoHash的计算方式，以及字符串长度对应的面大小。请参考如下这篇文章：<br><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/35940647">GeoHash算法学习讲解、解析及原理分析</a></p>
<p>以上就是我们实现基于GeoHash进行定位的基础。</p>
<h2 id="如何用Geohash实现快速定位"><a href="#如何用Geohash实现快速定位" class="headerlink" title="如何用Geohash实现快速定位"></a>如何用Geohash实现快速定位</h2><p>既然可以用经纬度代表的一个点得到一个面，那如果我们的历史数据足够多，映射出足够多的的面，这些面就会像拼图一样，慢慢把我们的世界拼出来。</p>
<p>例如我们可以用21个GeoHash字符串将整个北京欢乐谷拼出来：</p>
<p><img src="https://img-blog.csdnimg.cn/20191206171409523.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="wx4ffc"></p>
<p>有了这个完整的拼图之后，当欢乐谷范围内有一条新数据上报时，我们只需要根据经纬度算出对应的GeoHash值，再用这个值去和这21个字符串匹配，如果和其中任意一个相同，就说明此条数据的位置信息为中国北京的朝阳区（不具体定位到欢乐谷是因为我们最细粒度只划分到行政区)。</p>
<p>采用这个思路，最后我们将世界地图构建好之后，当有新数据需要定位时，我们只需要做一次GeoHash字符串计算，再到数据库中进行匹配即可。速度大大提高。</p>
<h2 id="示例代码"><a href="#示例代码" class="headerlink" title="示例代码"></a>示例代码</h2><h4 id="Geohash字符串的计算："><a href="#Geohash字符串的计算：" class="headerlink" title="Geohash字符串的计算："></a>Geohash字符串的计算：</h4><p>此处采用的方法是写一个UDF，UDF的功能是输入经纬度及想要的GeoHash字符串长度，输出对应的GeoHash字符串。再将其打成jar包，上传之后在hive中创建临时函数，再进行调用。</p>
<h5 id="首先导入依赖"><a href="#首先导入依赖" class="headerlink" title="首先导入依赖"></a>首先导入依赖</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">            &lt;groupId&gt;ch.hsr&lt;/groupId&gt;</span><br><span class="line">            &lt;artifactId&gt;geohash&lt;/artifactId&gt;</span><br><span class="line">            &lt;version&gt;1.3.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<h5 id="继承UDF并重写evaluate方法"><a href="#继承UDF并重写evaluate方法" class="headerlink" title="继承UDF并重写evaluate方法"></a>继承UDF并重写evaluate方法</h5><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">public class getGeoHashString extends UDF &#123;</span><br><span class="line"></span><br><span class="line">    private static int precision = 7;</span><br><span class="line"></span><br><span class="line">    public String evaluate(double latitude, double longtitude, int precisionParam) &#123;</span><br><span class="line"></span><br><span class="line">        GeoHash geoHash = GeoHash.withCharacterPrecision(latitude, longtitude, precisionParam);</span><br><span class="line">        return geoHash.toBase32();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public String evaluate(double latitude, double longtitude) &#123;</span><br><span class="line"></span><br><span class="line">        GeoHash geoHash = GeoHash.withCharacterPrecision(latitude, longtitude, precision);</span><br><span class="line">        return geoHash.toBase32();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>默认采用7位长度，当然也支持传入参数自定义</p>
<h5 id="Maven打包并上传"><a href="#Maven打包并上传" class="headerlink" title="Maven打包并上传"></a>Maven打包并上传</h5><p>略。。</p>
<h5 id="使用UDF"><a href="#使用UDF" class="headerlink" title="使用UDF"></a>使用UDF</h5><p>目前是在hive命令行中运行的，具体方法如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">add jar /data/home/geoHashUDF-1.0-SNAPSHOT-jar-with-dependencies.jar;</span><br></pre></td></tr></table></figure>
<p>先把jar包添加进来，在创建临时函数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TEMPORARY FUNCTION get_geohash_string as &#x27;getGeoHashString&#x27;;</span><br></pre></td></tr></table></figure>
<p>其中get_geohash_string为函数名，getGeoHashString为你的主类。</p>
<h5 id="接下来写SQL就可以了"><a href="#接下来写SQL就可以了" class="headerlink" title="接下来写SQL就可以了"></a>接下来写SQL就可以了</h5><p>将每一天的新数据计算后写入分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE TABLE geohash_a_d</span><br><span class="line">PARTITION(dt)</span><br><span class="line">SELECT</span><br><span class="line">get_geohash_string(latitude,longitude),</span><br><span class="line"></span><br><span class="line">geo_district_id,</span><br><span class="line">geo_district_name_en,</span><br><span class="line">geo_district_name_zh,</span><br><span class="line"></span><br><span class="line">geo_city_id,</span><br><span class="line">geo_city_name_en,</span><br><span class="line">geo_city_name_zh,</span><br><span class="line"></span><br><span class="line">geo_province_id,</span><br><span class="line">geo_province_name_en,</span><br><span class="line">geo_province_name_zh,</span><br><span class="line"></span><br><span class="line">geo_country_id,</span><br><span class="line">geo_country_name_en,</span><br><span class="line">geo_country_name_zh,</span><br><span class="line">dt</span><br><span class="line">from </span><br><span class="line">report_i_h</span><br><span class="line">WHERE </span><br><span class="line">dt BETWEEN &#x27;2019-11-01&#x27; AND &#x27;2019-11-30&#x27;</span><br></pre></td></tr></table></figure>
<p>对每一天的数据进行去重合并</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE TABLE geohash_summary</span><br><span class="line">SELECT </span><br><span class="line">geohash,</span><br><span class="line">geo_district_id,</span><br><span class="line">geo_district_name_en,</span><br><span class="line">geo_district_name_zh,</span><br><span class="line">geo_city_id,</span><br><span class="line">geo_city_name_en,</span><br><span class="line">geo_city_name_zh,</span><br><span class="line">geo_province_id,</span><br><span class="line">geo_province_name_en,</span><br><span class="line">geo_province_name_zh,</span><br><span class="line">geo_country_id,</span><br><span class="line">geo_country_name_en,</span><br><span class="line">geo_country_name_zh</span><br><span class="line">from geohash_a_d</span><br><span class="line">WHERE dt=&#x27;2019-11-01&#x27;</span><br><span class="line">UNION DISTINCT</span><br><span class="line">SELECT </span><br><span class="line">geohash,</span><br><span class="line">geo_district_id,</span><br><span class="line">geo_district_name_en,</span><br><span class="line">geo_district_name_zh,</span><br><span class="line">geo_city_id,</span><br><span class="line">geo_city_name_en,</span><br><span class="line">geo_city_name_zh,</span><br><span class="line">geo_province_id,</span><br><span class="line">geo_province_name_en,</span><br><span class="line">geo_province_name_zh,</span><br><span class="line">geo_country_id,</span><br><span class="line">geo_country_name_en,</span><br><span class="line">geo_country_name_zh</span><br><span class="line">from geohash_a_d</span><br><span class="line">WHERE dt BETWEEN &#x27;2019-11-02&#x27; AND &#x27;2019-11-30&#x27;</span><br></pre></td></tr></table></figure>
<p>对hash值进行去重，确保一个hash值只对应一条记录（<strong>此处有大坑，之后讲</strong>）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">with tmp as (</span><br><span class="line">SELECT </span><br><span class="line">geohash,</span><br><span class="line">geo_district_id,</span><br><span class="line">geo_district_name_en,</span><br><span class="line">geo_district_name_zh,</span><br><span class="line">geo_city_id,</span><br><span class="line">geo_city_name_en,</span><br><span class="line">geo_city_name_zh,</span><br><span class="line">geo_province_id,</span><br><span class="line">geo_province_name_en,</span><br><span class="line">geo_province_name_zh,</span><br><span class="line">geo_country_id,</span><br><span class="line">geo_country_name_en,</span><br><span class="line">geo_country_name_zh,</span><br><span class="line">row_number() OVER(PARTITION BY geohash ORDER BY </span><br><span class="line">geo_country_id,geo_province_id,geo_city_id,geo_district_id</span><br><span class="line">desc) as rank</span><br><span class="line">from geohash_summary</span><br><span class="line">where geo_country_id is not null</span><br><span class="line">)</span><br><span class="line">insert overwrite table geohash_distinct</span><br><span class="line">select</span><br><span class="line">geohash,</span><br><span class="line">geo_district_id,</span><br><span class="line">geo_district_name_en,</span><br><span class="line">geo_district_name_zh,</span><br><span class="line">geo_city_id,</span><br><span class="line">geo_city_name_en,</span><br><span class="line">geo_city_name_zh,</span><br><span class="line">geo_province_id,</span><br><span class="line">geo_province_name_en,</span><br><span class="line">geo_province_name_zh,</span><br><span class="line">geo_country_id,</span><br><span class="line">geo_country_name_en,</span><br><span class="line">geo_country_name_zh</span><br><span class="line">from tmp</span><br><span class="line">where rank=1</span><br></pre></td></tr></table></figure>
<p>这几个SQL跑完后，我们的GeoHash维度表就初步构建完成了。</p>
<h2 id="效果测试"><a href="#效果测试" class="headerlink" title="效果测试"></a>效果测试</h2><p>构建完成后，便可以进行定位的效果测试了，我们采用的测试方案是：<br>取不在回溯日期内的几天的数据，通过GeoHash的方式获取其位置信息，在和用geoSpark获取的位置信息作对比，校验其准确性。</p>
<p>结果：99.5%的数据可以成功获取定位信息，但是其中千分之七的数据存在distinct级的误差，千分之一的数据存在city级的误差。此外，还意外的实现了千分之一的数据优化。</p>
<p>数据优化：有一些数据可能geoSpark定位不到，或定位的信息不全，通过geoHash可以获取到定位或将定位信息补全。随便举个例子：<br>geoSpark:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">latitude:45.12345</span><br><span class="line">longtitude:110.12345</span><br><span class="line">dim_geohash_distinct.geo_district_id	null</span><br><span class="line">dim_geohash_distinct.geo_city_id	null</span><br><span class="line">dim_geohash_distinct.geo_province_id	3117</span><br><span class="line">dim_geohash_distinct.geo_country_id	3142</span><br></pre></td></tr></table></figure>
<p>geoHash:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">latitude:45.12345</span><br><span class="line">longtitude:110.12345</span><br><span class="line">dim_geohash_distinct.geo_district_id	132</span><br><span class="line">dim_geohash_distinct.geo_city_id	3022</span><br><span class="line">dim_geohash_distinct.geo_province_id	3117</span><br><span class="line">dim_geohash_distinct.geo_country_id	3142</span><br></pre></td></tr></table></figure>
<p>通过GeoHash，可以将缺失的district_id及city_id补全。</p>
<h2 id="补充"><a href="#补充" class="headerlink" title="补充"></a>补充</h2><p>采用GeoHash实现定位的前提是有足够的数据量支持，为了达到本文实现的效果，我们回溯了三个月的数据，每天的数据量在35亿左右。最后生成的维度表结构如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20191209104852237.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>其中district代表行政区（如东城区、朝阳区），geohash为生成的GeoHash字符串。<br>随便抽取其中一条记录如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20191209105347452.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>（话说以前一直以为西藏的英文是Xizang。。orz)</p>
<p>GeoHash这种方式虽然较快的实现了定位，但仍有一些问题丞待解决，下一篇文章将讨论这些坑以及可能的解决方案。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/catalog%E5%92%8Cschema%E7%9A%84%E5%8C%BA%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/catalog%E5%92%8Cschema%E7%9A%84%E5%8C%BA%E5%88%AB/" class="post-title-link" itemprop="url">catalog和schema的区别</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:45:56 / 修改时间：18:47:00" itemprop="dateCreated datePublished" datetime="2021-06-08T18:45:56+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据仓库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>直接上图，直观一点：</p>
<p><img src="https://img-blog.csdnimg.cn/20191210125223204.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="什么是catalog"><a href="#什么是catalog" class="headerlink" title="什么是catalog"></a>什么是catalog</h3><p>从概念上说，一个catalog包含多个schema，一个schema下可以包含多个数据库对象（表，视图，字段），catalog可以理解为数据库实例的元数据集合。</p>
<p>常用数据库对catalog和schema的支持如下：</p>
<p><img src="https://img-blog.csdnimg.cn/2019121012584136.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h3 id="什么是schema"><a href="#什么是schema" class="headerlink" title="什么是schema"></a>什么是schema</h3><p>一般来说，schema是指数据库表的组织和定义，定义了表、字段以及表和字段间的关系。可以理解为表的命名空间。</p>
<p>推荐下stack overflow上的优秀回答：<br> <a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/7022755/whats-the-difference-between-a-catalog-and-a-schema-in-a-relational-database">What’s the difference between a catalog and a schema in a relational database?
</a></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/Hive%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Hive%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89%E4%B9%8B%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/" class="post-title-link" itemprop="url">Hive入门之基础知识（一）之杂七杂八</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:41:57 / 修改时间：18:42:21" itemprop="dateCreated datePublished" datetime="2021-06-08T18:41:57+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="随笔总结一些关于Hive的杂七杂八的知识点"><a href="#随笔总结一些关于Hive的杂七杂八的知识点" class="headerlink" title="随笔总结一些关于Hive的杂七杂八的知识点"></a>随笔总结一些关于Hive的杂七杂八的知识点</h1><h2 id="Hive出现的原因"><a href="#Hive出现的原因" class="headerlink" title="Hive出现的原因"></a>Hive出现的原因</h2><p>从一个基于传统关系型数据库和结构化查询语言的数据基础架构转移到Hadoop上，使用HQL查询Hadoop中的数据。</p>
<h2 id="Hive与传统关系型数据库的区别"><a href="#Hive与传统关系型数据库的区别" class="headerlink" title="Hive与传统关系型数据库的区别"></a>Hive与传统关系型数据库的区别</h2><p>Hive不支持记录级别的更新、插入和删除操作。执行延迟大，不支持事务。</p>
<h2 id="Hive组成模块"><a href="#Hive组成模块" class="headerlink" title="Hive组成模块"></a>Hive组成模块</h2><p><img src="https://img-blog.csdnimg.cn/20191213140841632.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>所有的命令和查询都会进入到驱动模块driver中，driver对输入进行解析和编译，以及对需求的计算进行优化，然后启动MR来执行job。Hive本身不会生成MR的程序，而是通过一个表示”job执行计划“的XML文件驱动执行内置的原生的MR模块。<br>Hive通过和jobtracker进行通信来初始化MR任务。</p>
<h2 id="Hive安装目录"><a href="#Hive安装目录" class="headerlink" title="Hive安装目录"></a>Hive安装目录</h2><p><img src="https://img-blog.csdnimg.cn/20191213142812701.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h2 id="Hive常用的命令行执行参数"><a href="#Hive常用的命令行执行参数" class="headerlink" title="Hive常用的命令行执行参数"></a>Hive常用的命令行执行参数</h2><p>Hive -e执行完一条命令后立刻退出CLI<br>Hive -S开启静默模式，去掉OK等无关紧要的输出信息<br>Hive -f文件名，指定文件中的一个或多个查询语句。</p>
<h2 id="Hive的基本数据类型"><a href="#Hive的基本数据类型" class="headerlink" title="Hive的基本数据类型"></a>Hive的基本数据类型</h2><p><img src="https://img-blog.csdnimg.cn/2019121314530063.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br><img src="https://img-blog.csdnimg.cn/20191213145333149.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>其中时间戳可以是整数、浮点数、字符串，其表示的是UTC时间。</p>
<h4 id="类型转换的用法："><a href="#类型转换的用法：" class="headerlink" title="类型转换的用法："></a>类型转换的用法：</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cast(user_id AS STRING) as user_id_string</span><br></pre></td></tr></table></figure>

<h4 id="Hive中的集合数据类型"><a href="#Hive中的集合数据类型" class="headerlink" title="Hive中的集合数据类型"></a>Hive中的集合数据类型</h4><p>Hive中的集合数据类型：map、struct、array<br>为什么Hive支持集合数据类型，而大多数传统关系型数据库不支持：关系型数据库通过外键将多个表进行关联，当数据量很大时，根据外键进行关联造成的磁盘间的寻址操作将产生很高的代价。</p>
<h4 id="Hive的读时模式"><a href="#Hive的读时模式" class="headerlink" title="Hive的读时模式"></a>Hive的读时模式</h4><p>传统的关系型数据库是写时模式，在数据写入时对模式进行检查。<br>对于Hive要查询的数据，有很多种方式对其进行创建，修改，损坏，因此Hive采用读时模式，在查询时进行验证，尽量修复错误或者赋空值。</p>
<h4 id="Hive查看表信息"><a href="#Hive查看表信息" class="headerlink" title="Hive查看表信息"></a>Hive查看表信息</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">DESCRIBE  表名</span><br><span class="line">DESCRIBE EXTENDED 表名</span><br><span class="line">DESCRIBE FORMATTED 表名</span><br></pre></td></tr></table></figure>
<p>都可以查询表的详细信息，信息完整程度由上到下逐渐增加，DESCRIBE FORMATTED的数据最完整。</p>
<h2 id="外部表和内部表"><a href="#外部表和内部表" class="headerlink" title="外部表和内部表"></a>外部表和内部表</h2><p>内部表：也叫管理表，Hive会控制数据的生命周期，删除一个内部表时，Hive也会删除表中的数据。内部表也不便于和其他工作共享数据。<br>外部表：删除表并不会删除表中的数据，但是描述表的元数据信息会被删除。有些HQL的语法结构也不适用于外部表。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">CREATE EXTERNAL TABLE 目标表 LIKE 源表   -- 生成的表是外部表</span><br><span class="line">CREATE TABLE 目标表 LIKE 源表  -- 如果源表是外部表，则目标表也是外部表；如果源表是内部表，目标表也是内部表</span><br></pre></td></tr></table></figure>

<h2 id="Hive表的存储格式"><a href="#Hive表的存储格式" class="headerlink" title="Hive表的存储格式"></a>Hive表的存储格式</h2><p>默认情况下，Hive采用的存储格式为文本文件格式（TEXTFILE），在这种格式下，每一行被认为是一个单独的记录。<br>记录的解析由序列化器，反序列化器（SerDe）来控制。<br>Hive使用一个inputformat对象将输入流分割成记录，使用outputformat对象将记录格式化为输出流，使用SerDe在读数据时将记录解析成列，写数据时将列编码成记录。</p>
<h2 id="Hive防止表被删除或查询"><a href="#Hive防止表被删除或查询" class="headerlink" title="Hive防止表被删除或查询"></a>Hive防止表被删除或查询</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ALTER TABLE test ENABLE NO_DROP  // 防止被删除</span><br><span class="line">ALTER TABLE test ENABLE OFFLINE  // 防止被查询</span><br></pre></td></tr></table></figure>
<p>若要允许被删除或查询，只需把 enable 改为 disable </p>
<h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p>Hive没有关系型数据库中键的概念，只有有限的索引功能。一张表的索引数据存放在另一张表中。<br>建立索引可以帮助剪裁掉一张表的一些数据块，减少MR任务的数据输入量。<br>通过explain+SQL语句可以查看是否使用了索引。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/Spark%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Spark%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%80%EF%BC%89/" class="post-title-link" itemprop="url">Spark入门之基础知识（一）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:41:13 / 修改时间：18:41:39" itemprop="dateCreated datePublished" datetime="2021-06-08T18:41:13+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h4 id="什么是Spark"><a href="#什么是Spark" class="headerlink" title="什么是Spark"></a>什么是Spark</h4><p>Spark 是一个用来实现快速而通用的集群计算的平台。</p>
<h4 id="Spark的核心"><a href="#Spark的核心" class="headerlink" title="Spark的核心"></a>Spark的核心</h4><p>Spark 的核心是一个对由很多计算任务组成的、运行在多个工作机器或者一个计算集群上的应用  进行调度、分发、监控的计算引擎。</p>
<h4 id="Spark软件栈设计的优点"><a href="#Spark软件栈设计的优点" class="headerlink" title="Spark软件栈设计的优点"></a>Spark软件栈设计的优点</h4><p>1）软件栈中所有程序库和高级组件都可以从下层的改进中受益。<br>2）运行整个软件栈的代价变小了。<br>3）可以构建出无缝整合处理不同模型的应用。</p>
<h4 id="Spark-的各个组件"><a href="#Spark-的各个组件" class="headerlink" title="Spark 的各个组件"></a>Spark 的各个组件</h4><p>Spark的各个组件如图所示：<br><img src="https://img-blog.csdnimg.cn/20191216125136843.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>Spark Core：实现了Spark的基本功能，报包含任务调度，内存管理，错误恢复，与存储系统交互等模块，还包含了对RDD的API定义。</p>
<p>Spark SQL：Spark用来操作结构化数据的程序包。</p>
<p>SparkStreaming：提供了用来操作数据流的API。</p>
<p>MLib与GraghX目前不在学习计划内暂时不介绍。</p>
<h4 id="Spark核心概念简介"><a href="#Spark核心概念简介" class="headerlink" title="Spark核心概念简介"></a>Spark核心概念简介</h4><p>每个Spark应用都由一个驱动器程序发起集群上的各种并行操作。驱动器程序通过SparkContext对象访问Spark，这个对象代表对计算集群的一个连接。驱动器程序还要管理多个执行器节点。<br><img src="https://img-blog.csdnimg.cn/20191216141248477.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下篇文章介绍Spark的RDD编程。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/Spark%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89RDD%E7%BC%96%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Spark%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89RDD%E7%BC%96%E7%A8%8B/" class="post-title-link" itemprop="url">Spark入门之基础知识（二）RDD编程</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:40:29 / 修改时间：18:40:55" itemprop="dateCreated datePublished" datetime="2021-06-08T18:40:29+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="什么是RDD"><a href="#什么是RDD" class="headerlink" title="什么是RDD"></a>什么是RDD</h2><p>弹性分布式数据集RDD是Spark的核心抽象。RDD其实就是分布式的元素集合，Spark中的操作创建、转化、或对RDD进行求值，Spark会自动将RDD的数据分发到集群上并并行执行。<br>RDD是一个不可变的分布式对象集合，每个RDD都被分为多个分区，这些分区在集群中不同的节点上运行。<br>”弹性“的解读：弹性意味着在任何时候都能进行重算，当某一部分数据丢失时，可以根据血缘关系将丢失的部分计算出来，而不是从头开始计算全部数据。</p>
<h2 id="RDD的属性"><a href="#RDD的属性" class="headerlink" title="RDD的属性"></a>RDD的属性</h2><p>（1）一组分片（Partition），即数据集的基本组成单位。对于RDD来说，每个分片都会被一个计算任务处理，并决定并行计算的粒度。用户可以在创建RDD时指定RDD的分片个数，如果没有指定，那么就会采用默认值。默认值就是程序所分配到的CPU Core的数目。</p>
<p>（2）一个计算每个分区的函数。Spark中RDD的计算是以分片为单位的，每个RDD都会实现compute函数以达到这个目的。compute函数会对迭代器进行复合，不需要保存每次计算的结果。</p>
<p>（3）RDD之间的依赖关系。RDD的每次转换都会生成一个新的RDD，所以RDD之间就会形成类似于流水线一样的前后依赖关系。在部分分区数据丢失时，Spark可以通过这个依赖关系重新计算丢失的分区数据，而不是对RDD的所有分区进行重新计算。</p>
<p>（4）一个Partitioner，即RDD的分片函数。当前Spark中实现了两种类型的分片函数，一个是基于哈希的HashPartitioner，另外一个是基于范围的RangePartitioner。只有对于于key-value的RDD，才会有Partitioner，非key-value的RDD的Parititioner的值是None。Partitioner函数不但决定了RDD本身的分片数量，也决定了parent RDD Shuffle输出时的分片数量。</p>
<p>（5）一个列表，存储存取每个Partition的优先位置（preferred location）。对于一个HDFS文件来说，这个列表保存的就是每个Partition所在的块的位置。按照“移动数据不如移动计算”的理念，Spark在进行任务调度的时候，会尽可能地将计算任务分配到其所要处理数据块的存储位置。</p>
<h2 id="创建RDD的方法"><a href="#创建RDD的方法" class="headerlink" title="创建RDD的方法"></a>创建RDD的方法</h2><p>1）读取外部数据及</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val lines = sc.textFile(&quot;test.txt&quot;) // 从HDFS读取数据</span><br></pre></td></tr></table></figure>
<p>读取数据的操作同样也是惰性的，执行上面这行代码时，数据并没有真正被读取进来。<br>2）在Driver Program中分发驱动器程序中的对象集合。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">val data = context.parallelize(List(1,2,3,4,5)) // 创建RDD最简单的方式</span><br></pre></td></tr></table></figure>
<h2 id="RDD的操作方法"><a href="#RDD的操作方法" class="headerlink" title="RDD的操作方法"></a>RDD的操作方法</h2><p>1）转化操作：transformation 会由一个RDD生成一个<em>新的</em>RDD。<br>Spark使用血缘关系图来记录不同RDD之间的依赖关系：<br><img src="https://img-blog.csdnimg.cn/201912161540010.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>2）行动操作：action会将RDD计算出一个结果，返回到Driver Program中或存到HDFS等外部存储中。</p>
<h5 id="转化操作和行动操作的区别"><a href="#转化操作和行动操作的区别" class="headerlink" title="转化操作和行动操作的区别"></a>转化操作和行动操作的区别</h5><p>transformation是惰性的，一个transformation操作并不会被立即计算，只有在action中用到时，才会去真正的计算。<br>转化操作返回的是一个RDD，行动操作返回的是其他的数据类型。</p>
<h5 id="为什么要区分转化和行动操作"><a href="#为什么要区分转化和行动操作" class="headerlink" title="为什么要区分转化和行动操作"></a>为什么要区分转化和行动操作</h5><p>主要是出于对资源和效率上的考虑，如果我们有1000行文本，先把前800行读出来记为RDD1，再将RDD1的前200行读出来记为RDD2，再读取RDD2的第一行记为RDD3，最后把RDD3存到HDFS上。<br>如果每一步都立刻计算的话，就会造成很大的开销。然而事实上我们只需要第一行的数据，在采取惰性计算后，在真正的action被执行时，Spark已经获知了整个转化操作链，只会计算我们真正需要的数据，大大加快了执行速度。</p>
<h2 id="关于RDD缓存"><a href="#关于RDD缓存" class="headerlink" title="关于RDD缓存"></a>关于RDD缓存</h2><h5 id="为什么要缓存"><a href="#为什么要缓存" class="headerlink" title="为什么要缓存"></a>为什么要缓存</h5><p>RDD会在每次对其进行action操作时重新计算，实际生产中很多情况下需要多次重用一个RDD（例如我们读取了一个大宽表，之后在这个宽表上产出各种维度数据），此时最好对RDD进行缓存。</p>
<h2 id="常见transformation与action操作讲解"><a href="#常见transformation与action操作讲解" class="headerlink" title="常见transformation与action操作讲解"></a>常见transformation与action操作讲解</h2><h4 id="transformation"><a href="#transformation" class="headerlink" title="transformation"></a>transformation</h4><p>1）map()：接受一个函数，将其应用于RDD中的每个元素，将函数返回值作为结果RDD中元素的对应值。返回值类型不需要和输入值类型一样。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">val data = context.parallelize(List(1,2,3,4,5))</span><br><span class="line">    val dataAdd = data.map(x =&gt; x+1)</span><br><span class="line">    dataAdd.take(6)</span><br></pre></td></tr></table></figure>
<p>对每一个元素加一，结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res11: Array[Int] = Array(2, 3, 4, 5, 6)</span><br></pre></td></tr></table></figure>
<p>2）filter()：接受一个函数，将RDD中满足函数要求的元素放入结果RDD中返回。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val dataFilter = data.filter(x =&gt; x &gt; 3)</span><br><span class="line">   dataFilter.take(5)</span><br></pre></td></tr></table></figure>
<p>筛选出大于3的元素，结果为：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">res12: Array[Int] = Array(4, 5)</span><br></pre></td></tr></table></figure>
<p>3）flatMap()：对每个输入元素生成多个输出元素，可以理解为将输入的RDD拍扁。<br><img src="https://img-blog.csdnimg.cn/20191216161042645.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>经过flatmap拍扁之后，得到的是一个由各列表中元素组成的RDD，而不是一个由多列表组成的RDD。</p>
<h5 id="RDD集合操作"><a href="#RDD集合操作" class="headerlink" title="RDD集合操作"></a>RDD集合操作</h5><p>集合操作要求RDD之间的数据类型相同。<br>1）union操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1 = context.parallelize(List(1, 3, 5, 7, 10))</span><br><span class="line">val rdd2 = context.parallelize(List(2, 4, 6, 8, 10))</span><br><span class="line">val union = rdd1.union(rdd2)</span><br><span class="line">union.take(10)</span><br><span class="line">res14: Array[Int] = Array(1, 3, 5, 7, 10, 2, 4, 6, 8, 10)</span><br></pre></td></tr></table></figure>
<p>返回包含两个RDD中全部元素的新RDD，重复元素也会保留。</p>
<p>2）intersection操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1 = context.parallelize(List(1, 3, 5, 7, 10))</span><br><span class="line">val rdd2 = context.parallelize(List(2, 4, 6, 8, 10))</span><br><span class="line">val intersection = rdd1.intersection(rdd2)</span><br><span class="line">intersection.take(10)</span><br><span class="line">res15: Array[Int] = Array(10)   </span><br></pre></td></tr></table></figure>
<p>结果为两个RDD的交集，会对结果去重。</p>
<p>3）subtract操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1 = context.parallelize(List(1, 3, 5, 7, 10))</span><br><span class="line">val rdd2 = context.parallelize(List(2, 4, 6, 8, 10))</span><br><span class="line">val sub = rdd1.subtract(rdd2)</span><br><span class="line">sub.take(10)</span><br><span class="line">res16: Array[Int] = Array(1, 3, 5, 7)         </span><br></pre></td></tr></table></figure>
<p>返回存在第一个RDD中，不存在第二个RDD中的元素</p>
<p>4）cartesian操作：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val rdd1 = sc.parallelize(List(1, 3, 5))</span><br><span class="line">val rdd2 = sc.parallelize(List(2, 4, 6))</span><br><span class="line">val cartesian = rdd1.cartesian(rdd2)</span><br><span class="line">cartesian.take(9)</span><br><span class="line">res17: Array[(Int, Int)] = Array((1,2), (1,4), (1,6), (3,2), (5,2), (3,4), (3,6), (5,4), (5,6))</span><br></pre></td></tr></table></figure>
<p>对两个RDD求笛卡尔积</p>
<h4 id="action"><a href="#action" class="headerlink" title="action"></a>action</h4><p>1）reduce：<br>操作两个RDD元素类型的数据并返回一个同样类型的新元素</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; list</span><br><span class="line">res0: List[Int] = List(1, 2, 3, 4, 5)</span><br><span class="line">scala&gt; list.reduce((x,y) =&gt; x+y)</span><br><span class="line">res2: Int = 15</span><br></pre></td></tr></table></figure>

<p>2）fold：<br>与reduce相同，只不过加了个初始值的设定<br>初始值为100，最后求和结果为115</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; list</span><br><span class="line">res0: List[Int] = List(1, 2, 3, 4, 5)</span><br><span class="line">scala&gt; list.fold(100)((x,y) =&gt; x+y)</span><br><span class="line">res3: Int = 115</span><br></pre></td></tr></table></figure>
<p>3）aggregate：<br>reduce和fold都只能返回和RDD中元素类型相同的值，例如前面的例子中。list中的是int，那么我们最后得到的返回值也是int，但是aggregate却没有这个限制，可以有不同类型的返回值。<br>举个经典的求平均值例子：<br>aggregate采用柯里化的方式接受三个参数，在本例中(0,0)代表初始值，第一个函数(x, y) =&gt; (x._1 + y, x._2 + 1)代表（目前已统计的数值之和，目前已统计的元素个数），第二个函数(x, y) =&gt; (x._1 + y._1, x._2 + y._2)代表对分布式计算的结果进行累加计算，例如从两个RDD统计的结果为（10，2），（10，3），对这两部分进行合并得到（20，5），最后用20/5即可得到平均值。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val data = sc.parallelize(List(1,2,3,4,5))</span><br><span class="line">data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:24</span><br><span class="line">scala&gt; val result = data.aggregate(0, 0)((x, y) =&gt; (x._1 + y, x._2 + 1), (x, y) =&gt; (x._1 + y._1, x._2 + y._2))</span><br><span class="line">result: (Int, Int) = (15,5)</span><br><span class="line">scala&gt; val avg = result._1/result._2.toDouble</span><br><span class="line">avg: Double = 3.0                                                     </span><br></pre></td></tr></table></figure>
<p>4）collect：<br>会将整个RDD的内容返回，要求所有数据都必须能一同放入单台机器的内存中。所以不建议在数据量很大时使用，一般用来测试代码。<br>5）take：<br>返回RDD中的n个元素</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; list</span><br><span class="line">res0: List[Int] = List(1, 2, 3, 4, 5)</span><br><span class="line">scala&gt; list.take(3)</span><br><span class="line">res4: List[Int] = List(1, 2, 3)</span><br></pre></td></tr></table></figure>
<p>6）top：<br>从RDD中提取前n个元素</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; val data = sc.parallelize(List(1,2,3,4,5))</span><br><span class="line">data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at &lt;console&gt;:24</span><br><span class="line">scala&gt; data.top(2)</span><br><span class="line">res10: Array[Int] = Array(5, 4)</span><br></pre></td></tr></table></figure>
<p>7）takeSample：<br>从数据采样<br>该方法仅在预期结果数组很小的情况下使用，因为所有数据都被加载到driver的内存中。<br>第一个参数true or false 表示是否可以重复抽样，在选为false的情况下，抽取的元素不会发生重复。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; data.takeSample(false,2)</span><br><span class="line">res11: Array[Int] = Array(4, 1)       </span><br><span class="line">scala&gt; data.takeSample(false,2)</span><br><span class="line">res12: Array[Int] = Array(2, 4) </span><br></pre></td></tr></table></figure>

<h4 id="缓存"><a href="#缓存" class="headerlink" title="缓存"></a>缓存</h4><p>当我们对RDD进行缓存时，计算出RDD的节点会分别保存他们计算出的数据，如果某个节点的数据丢失，当我们用到RDD时，Spark会重算这部分的数据。<br>在Scala中，默认情况下persist()会把数据以序列化的形式缓存在JVM的堆空间中。</p>
<p>各个缓存级别的差异如图所示：<br><img src="https://img-blog.csdnimg.cn/20191217153950699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>persist()的调用不会触发求值，当缓存的数据太多内存放不下时，Spark会使用LRU删除最近最少使用的那部分数据，如果缓存级别为只放在内存中时，再次用到这部分的数据就需要重新计算。</p>
<p>下篇文章将介绍基本的键值对操作。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/Hive%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B9%8B%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E4%B8%8E%E6%9F%A5%E8%AF%A2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Hive%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%BA%8C%EF%BC%89%E4%B9%8B%E6%95%B0%E6%8D%AE%E6%93%8D%E4%BD%9C%E4%B8%8E%E6%9F%A5%E8%AF%A2/" class="post-title-link" itemprop="url">Hive入门之基础知识（二）之数据操作与查询</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:38:57 / 修改时间：18:39:58" itemprop="dateCreated datePublished" datetime="2021-06-08T18:38:57+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="向Hive表中装载数据"><a href="#向Hive表中装载数据" class="headerlink" title="向Hive表中装载数据"></a>向Hive表中装载数据</h2><p>Hive不会验证向表中装载的数据和表的模式是否匹配（需要自己检查确认），但是会检查文件的格式是否和表结构定义的一致（创建表时指定的结构若为SEQUENCEFILE，则装载进去的文件也应该为sequencefile格式）。</p>
<p>从本地文件系统向表中装载数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &#x27;path&#x27; INTO TABLE &#x27;table&#x27;  </span><br></pre></td></tr></table></figure>

<p>从本地文件系统向表中装载数据，使用overwrite覆盖原表数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &#x27;path&#x27; OVERWRITE INTO TABLE &#x27;table&#x27;</span><br></pre></td></tr></table></figure>


<p>从本地文件系统向表中装载数据，使用overwrite覆盖原表数据并指定时间分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &#x27;path&#x27; OVERWRITE INTO TABLE &#x27;table&#x27; PARTITION (dt=&#x27;2019-11-11&#x27;)</span><br></pre></td></tr></table></figure>

<p>从HDFS向表中装载数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA INPATH &#x27;path&#x27; INTO TABLE &#x27;table&#x27;  </span><br></pre></td></tr></table></figure>

<p>从HDFS向表中装载数据，使用overwrite覆盖原表数据</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA INPATH &#x27;path&#x27; OVERWRITE INTO TABLE &#x27;table&#x27;</span><br></pre></td></tr></table></figure>



<p>从HDFS向表中装载数据，使用overwrite覆盖原表数据并指定时间分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD DATA LOCAL INPATH &#x27;path&#x27; OVERWRITE INTO TABLE &#x27;table&#x27; PARTITION (dt=&#x27;2019-11-11&#x27;)</span><br></pre></td></tr></table></figure>

<p>另外需要注意的是，如果使用了local关键字，数据将会被<strong>拷贝</strong>到目标位置，<br>如果不使用local关键字，数据会被<strong>转移</strong>到目标位置。因为Hive默认在分布式文件系统中用户不需要一份文件的多份重复拷贝。</p>
<h2 id="通过查询语句向表中装载数据"><a href="#通过查询语句向表中装载数据" class="headerlink" title="通过查询语句向表中装载数据"></a>通过查询语句向表中装载数据</h2><p>PARTITION关键字可以指定要创建的分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE TABLE &#x27;table1&#x27;</span><br><span class="line">PARTITION(dt=&#x27;2019-11-11&#x27;)</span><br><span class="line">SELECT * FROM &#x27;table2&#x27;</span><br><span class="line">WHERE dt=&#x27;2019-11-11&#x27;</span><br></pre></td></tr></table></figure>
<h4 id="动态分区插入"><a href="#动态分区插入" class="headerlink" title="动态分区插入"></a>动态分区插入</h4><p>当分区很多时，一个一个指定很麻烦，可以使用动态分区插入<br>需要先开启动态分区</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SET hive.exec.dynamic.partition = true       </span><br><span class="line">SET hive.exec.dynamic.partition.mode = nostrict</span><br></pre></td></tr></table></figure>
<p>使用动态分区插入：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">将表2中11-01号到11-11号的user_id按时间分区插入到表1中</span><br><span class="line">INSERT OVERWRITE TABLE &#x27;table1&#x27;</span><br><span class="line">PARTITION(dt)</span><br><span class="line">SELECT </span><br><span class="line">user_id,</span><br><span class="line">dt</span><br><span class="line">from &#x27;table2&#x27;</span><br><span class="line">WHERE dt BETWEEN &#x27;2019-11-01&#x27; AND &#x27;2019-11-11&#x27;</span><br></pre></td></tr></table></figure>
<p>还可以通过一个查询语句直接创建出表，在实际工作中长使用此功能创建临时表</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE tmp AS</span><br><span class="line">SELECT</span><br><span class="line">user_id,</span><br><span class="line">dt,</span><br><span class="line">hour</span><br><span class="line">from table1</span><br></pre></td></tr></table></figure>
<h2 id="导出数据"><a href="#导出数据" class="headerlink" title="导出数据"></a>导出数据</h2><p>如果数据恰好是所需要的格式，直接从HDFS上拷贝文件即可。<br>如果不是需要的格式，可以参考如下示例，Hive会将所有字段序列化成字符串写入到文件中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE LOCAL DIRECTORY &#x27;yourPath&#x27;</span><br><span class="line">SELECT</span><br><span class="line">user_id,</span><br><span class="line">name,</span><br><span class="line">dt,</span><br><span class="line">hour</span><br><span class="line">from yourTable</span><br></pre></td></tr></table></figure>
<h2 id="如何引用集合类型中的元素"><a href="#如何引用集合类型中的元素" class="headerlink" title="如何引用集合类型中的元素"></a>如何引用集合类型中的元素</h2><h4 id="array"><a href="#array" class="headerlink" title="array"></a>array</h4><p>数组的索引从0开始，使用array[索引]的语法，引用一个不存在的元素将返回null</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT user_info[0] from user_detail</span><br></pre></td></tr></table></figure>
<h4 id="map"><a href="#map" class="headerlink" title="map"></a>map</h4><p>与array相同，使用array[…]的语法，不过使用对应的key值而不是索引</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT user_info[&quot;location&quot;] from user_detail</span><br></pre></td></tr></table></figure>
<h4 id="struct"><a href="#struct" class="headerlink" title="struct"></a>struct</h4><p>使用 点 <strong><font color='yellow'>.</font></strong> 符号</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT address.city from user_detail</span><br></pre></td></tr></table></figure>

<h2 id="如何解决算术计算中可能的上溢或下溢问题"><a href="#如何解决算术计算中可能的上溢或下溢问题" class="headerlink" title="如何解决算术计算中可能的上溢或下溢问题"></a>如何解决算术计算中可能的上溢或下溢问题</h2><p>1）使用范围更广的数据类型，但会占用更多空间。<br>2）进行缩放，除以10、100、1000等，还可以取log值进行计算。</p>
<h2 id="可以进行数据类型转换的函数"><a href="#可以进行数据类型转换的函数" class="headerlink" title="可以进行数据类型转换的函数"></a>可以进行数据类型转换的函数</h2><p>floor、round、ceil，输入的是double类型，返回值为bigint类型。在进行数据类型转换时，这些函数是首选的处理方式。</p>
<h2 id="什么情况下Hive可以避免产生一个MR任务"><a href="#什么情况下Hive可以避免产生一个MR任务" class="headerlink" title="什么情况下Hive可以避免产生一个MR任务"></a>什么情况下Hive可以避免产生一个MR任务</h2><p>1）本地模式，如 select * from table ，不会产生MR，Hive会直接读取存储目录下的文件，输出格式化后的数据。<br>2）在where子句中只有分区字段时，也不会产生MR。 </p>
<h2 id="Hive的join优化"><a href="#Hive的join优化" class="headerlink" title="Hive的join优化"></a>Hive的join优化</h2><p>大多数情况下，Hive会对每对join对象启动一个MR任务，但如果对3个或3个以上的表进行join时，on条件使用了相同的连接键，只会产生一个MR任务。</p>
<h2 id="order-by与sort-by"><a href="#order-by与sort-by" class="headerlink" title="order by与sort by"></a>order by与sort by</h2><p>order by：对结果执行全局排序，所有数据全部放在一个reducer中执行，当数据量很大时，会执行很长时间。<br>sort by：只会在每个reducer中进行排序，即局部排序。可以保证每个reducer输出的结果是有序的，但是不同reducer输出的结果可能会有重复的。</p>
<h2 id="distribute-by语句的使用"><a href="#distribute-by语句的使用" class="headerlink" title="distribute by语句的使用"></a>distribute by语句的使用</h2><p>distribute by控制map的输出在reduce中是如何划分的，可以指定distribute by的值，将相同值得数据分发到一个reducer中去，类似于group by。在分发后的数据中可以调用sort by 进行reducer内部的排序。<br>按用户ID做distribute，再按客户端时间做排序</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">SELECT</span><br><span class="line">* </span><br><span class="line">from your_table</span><br><span class="line">DISTRIBUTE BY user_id</span><br><span class="line">SORT BY client_event_time</span><br></pre></td></tr></table></figure>
<p>当distribute by和sort by中的字段相同时，可以使用<strong>cluster by</strong>做替代，达成相同的效果，但是使用cluster by会剥夺sort by的并行性，而且cluster by也不能指定ASC或者desc，只能按降序排列，但是可以实现数据的全局有序。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://jiangzhiqi4551.github.io/2021/06/08/Hive%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%89%EF%BC%89%E4%B9%8B%E5%88%86%E5%8C%BA%E4%B8%8E%E4%BC%98%E5%8C%96%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Hive%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%89%EF%BC%89%E4%B9%8B%E5%88%86%E5%8C%BA%E4%B8%8E%E4%BC%98%E5%8C%96%E7%9A%84%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">Hive入门之基础知识（三）之分区与优化的简单介绍</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:38:19 / 修改时间：18:38:42" itemprop="dateCreated datePublished" datetime="2021-06-08T18:38:19+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="为什么要对数据进行分区"><a href="#为什么要对数据进行分区" class="headerlink" title="为什么要对数据进行分区"></a>为什么要对数据进行分区</h2><p>在实际生产中，每天的数据量都是以亿为单位的，如果我们不对数据进行分区，直接对全部数据进行统计，则会大大增加时间开销，浪费大量资源。当我们做了合理分区后，例如按天进行分区，当查找某一天的数据时，Hive不会读取全部文件，只会读取HDFS中该天对应的目录，大大提高了执行效率。</p>
<h2 id="分区是不是越多越好"><a href="#分区是不是越多越好" class="headerlink" title="分区是不是越多越好"></a>分区是不是越多越好</h2><p>多数情况下，对数据可以按天进行分区，如果数据量还是太大，可以考虑再按小时进行分区，或者取另一个维度作为分区条件，在此基础上，还可以按分钟，秒进行分区，但是进行过多的分区并不一定会加快查询执<br>行效率。</p>
<p>使用过多的分区可能导致创建了很多非必须的Hadoop文件和文件夹，一个分区对应着一个包含了多个文件的文件夹。如果对表进行过多分区，又存储了跨度很久的数据，最后就会超出NameNode对系统的管理能力，因为NameNode必须保存文件系统的元数据信息，当小文件过多时，会限制HDFS所能管理的文件总数上限。</p>
<p>另外，MR会将一个job转化为多个task，默认情况下，每个task都是一个新的JVM实例，而JVM的开启和销毁都是需要时间开销的，对于每个小文件产生的task，JVM创建和销毁的开销可能会大于对文件内容本身进行处理的开销。</p>
<p>此外，默认情况下，Hive还会限制动态分区可以创建的最大分区数。</p>
<h4 id="对数据进行分桶"><a href="#对数据进行分桶" class="headerlink" title="对数据进行分桶"></a>对数据进行分桶</h4><p>分桶是将数据集分解为更容易管理的若干部分的另一种方法。</p>
<p>以下将创建一个按时间分区，使用user_id作为分桶字段的测试表，user_id会根据我们指定的值（此处为233，分桶数）进行哈希，分发到桶中。根据哈希算法的特性，同一个user_id的数据会分发到一个桶中，而享有相同哈希值的不同user_id的数据也会分发到一个桶中。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS test(</span><br><span class="line">user_id STRING COMMENT &#x27;用户ID&#x27;,</span><br><span class="line">user_age SMALLINT COMMENT &#x27;用户年龄&#x27;,</span><br><span class="line">user_identify STRING COMMENT &#x27;用户身份证号&#x27;,</span><br><span class="line">url STRING COMMENT &#x27;用户访问的URL&#x27;</span><br><span class="line">)</span><br><span class="line">PARTITIONED BY (dt STRING COMMENT &#x27;时间&#x27;)</span><br><span class="line">CLUSTERED BY (user_id) INTO 233 BUCKETS</span><br></pre></td></tr></table></figure>

<p>向分桶表中插入数据也和其他表有些区别，我们要设置一个属性强制为分桶表设置正确的reducer个数，然后执行SQL语句。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.enforce.bucketing = true</span><br></pre></td></tr></table></figure>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">INSERT OVERWRITE TABLE test</span><br><span class="line">PARTITION(dt=&#x27;2019-11-11&#x27;)</span><br><span class="line">SELECT</span><br><span class="line">user_id,</span><br><span class="line">user_age,</span><br><span class="line">user_identify,</span><br><span class="line">url</span><br><span class="line">FROM your_table</span><br><span class="line">WHERE dt = &#x27;2019-11-11&#x27;</span><br></pre></td></tr></table></figure>

<p>使用分桶的优点：桶的数量是固定的，所以分桶没有数据波动，适合于进行抽样。分桶还有利于执行高效的map-side join。</p>
<h2 id="JVM重用"><a href="#JVM重用" class="headerlink" title="JVM重用"></a>JVM重用</h2><p>Hadoop的默认配置是采用派生JVM来执行map和reduce的，当小文件比较多时JVM的创建和销毁会造成很大的开销。而JVM重用可以使同一个JVM在一个job中重用多次，减小频繁创建销毁JVM的开销。</p>
<h6 id="JVM重用的缺点："><a href="#JVM重用的缺点：" class="headerlink" title="JVM重用的缺点："></a>JVM重用的缺点：</h6><p>开启JVM重用后，会一直占用使用到的task插槽，以便进行重用，直到任务完成。如果某个reduce过程非常长的话，其他插槽虽然是空着的，但是必须等到该reduce执行完才能释放，无法被其他的job使用，造成资源浪费。</p>
<h2 id="limit语句的优化"><a href="#limit语句的优化" class="headerlink" title="limit语句的优化"></a>limit语句的优化</h2><p>Hive中，很多情况下虽然使用了limit，但还是要将这个语句执行完，再返回一部分。为了避免这个情况，可以考虑开启limit优化</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.limit.optimize.enable = true // 默认为false</span><br></pre></td></tr></table></figure>
<p>不过，将这个功能开启后，可能导致输入中有用的数据永远不会被处理到。</p>
<h2 id="Join优化"><a href="#Join优化" class="headerlink" title="Join优化"></a>Join优化</h2><p>在我们平时写SQL的过程中，可以将最大的表放在最右边，Hive会自动帮我们进行优化。<br>如果所有表中有一个表足够小可以存入内存中，Hive此时可以执行一个map-side join，减少reduce过程。</p>
<h2 id="并行执行"><a href="#并行执行" class="headerlink" title="并行执行"></a>并行执行</h2><p>Hive会将一个任务转化成一个或者多个stage，不同阶段有可能不存在依赖关系，这是开启并行执行就会加快整个任务的执行过程。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.exec.parallel = true</span><br></pre></td></tr></table></figure>


<h2 id="关于Hive的严格模式"><a href="#关于Hive的严格模式" class="headerlink" title="关于Hive的严格模式"></a>关于Hive的严格模式</h2><p>在Hive的严格模式下，一些类型的查询语句是被禁止执行的，因为这些语句可能会产生一个巨大的MR任务（例如两个十亿级数据量的表做join）。</p>
<p>在严格模式下，三种类型的操作将被禁止：<br>1）对分区表的查询中，where条件没有对分区字段做限制。<br>2）使用order by子句时，没有用limit做限制。当order by时，会将所有结果分发到一个reducer中进行排序，如果不进行限制，可能会执行很长时间。<br>3）限制笛卡尔积 （join）</p>
<p>不过在确实需要执行某些语句的情况下，可以关闭严格模式：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.mapred.mode = nostrict;</span><br></pre></td></tr></table></figure>



<h2 id="reducer个数的调整"><a href="#reducer个数的调整" class="headerlink" title="reducer个数的调整"></a>reducer个数的调整</h2><p>reducer设置的过多会导致job在运行过程中产生过多开销，还可能会消耗集群中过多的插槽，降低其他任务的运行效率，设置的过少会降低并行性。<br>HIve默认的reducer个数为3，可以通过</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set mapred.reduce.tasks = number</span><br></pre></td></tr></table></figure>
<p>中number值的设置调整reducer个数。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Master Jiang</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
