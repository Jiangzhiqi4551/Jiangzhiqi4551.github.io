<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.3/css/all.min.css" integrity="sha256-2H3fkXt6FEmrReK448mDVGKb3WW2ZZw35gI7vqHOE4Y=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{&quot;hostname&quot;:&quot;example.com&quot;,&quot;root&quot;:&quot;&#x2F;&quot;,&quot;images&quot;:&quot;&#x2F;images&quot;,&quot;scheme&quot;:&quot;Pisces&quot;,&quot;version&quot;:&quot;8.5.0&quot;,&quot;exturl&quot;:false,&quot;sidebar&quot;:{&quot;position&quot;:&quot;left&quot;,&quot;display&quot;:&quot;post&quot;,&quot;padding&quot;:18,&quot;offset&quot;:12},&quot;copycode&quot;:false,&quot;bookmark&quot;:{&quot;enable&quot;:false,&quot;color&quot;:&quot;#222&quot;,&quot;save&quot;:&quot;auto&quot;},&quot;fancybox&quot;:false,&quot;mediumzoom&quot;:false,&quot;lazyload&quot;:false,&quot;pangu&quot;:false,&quot;comments&quot;:{&quot;style&quot;:&quot;tabs&quot;,&quot;active&quot;:null,&quot;storage&quot;:true,&quot;lazyload&quot;:false,&quot;nav&quot;:null},&quot;motion&quot;:{&quot;enable&quot;:true,&quot;async&quot;:false,&quot;transition&quot;:{&quot;post_block&quot;:&quot;fadeIn&quot;,&quot;post_header&quot;:&quot;fadeInDown&quot;,&quot;post_body&quot;:&quot;fadeInDown&quot;,&quot;coll_header&quot;:&quot;fadeInLeft&quot;,&quot;sidebar&quot;:&quot;fadeInUp&quot;}},&quot;prism&quot;:false,&quot;i18n&quot;:{&quot;placeholder&quot;:&quot;搜索...&quot;,&quot;empty&quot;:&quot;没有找到任何搜索结果：${query}&quot;,&quot;hits_time&quot;:&quot;找到 ${hits} 个搜索结果（用时 ${time} 毫秒）&quot;,&quot;hits&quot;:&quot;找到 ${hits} 个搜索结果&quot;}}</script><script src="/js/config.js"></script>
<meta property="og:type" content="website">
<meta property="og:title" content="Jiang&#39;s blog">
<meta property="og:url" content="http://example.com/page/2/index.html">
<meta property="og:site_name" content="Jiang&#39;s blog">
<meta property="og:locale" content="zh_CN">
<meta property="article:author" content="Master Jiang">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/page/2/">



<script class="next-config" data-name="page" type="application/json">{&quot;sidebar&quot;:&quot;&quot;,&quot;isHome&quot;:true,&quot;isPost&quot;:false,&quot;lang&quot;:&quot;zh-CN&quot;,&quot;comments&quot;:&quot;&quot;,&quot;permalink&quot;:&quot;&quot;,&quot;path&quot;:&quot;page&#x2F;2&#x2F;index.html&quot;,&quot;title&quot;:&quot;&quot;}</script>

<script class="next-config" data-name="calendar" type="application/json">&quot;&quot;</script>
<title>Jiang's blog</title>
  




  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Jiang's blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li>
        <li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li>
        <li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li>
        <li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Master Jiang"
      src="/images/logo1.jpeg">
  <p class="site-author-name" itemprop="name">Master Jiang</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">23</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/Jiangzhiqi4551" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;Jiangzhiqi4551" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:Jiangzhiqi4551@outlook.com" title="E-Mail → mailto:Jiangzhiqi4551@outlook.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Jiangzhiqi4551?spm=1000.2115.3001.5343" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Jiangzhiqi4551?spm&#x3D;1000.2115.3001.5343" rel="noopener" target="_blank"><i class="fas fa-blog fa-fw"></i>CSDN</a>
      </span>
  </div>



        </div>
      </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/Spark%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%89%EF%BC%89%E9%94%AE%E5%80%BC%E5%AF%B9%E6%93%8D%E4%BD%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Spark%E5%85%A5%E9%97%A8%E4%B9%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%EF%BC%88%E4%B8%89%EF%BC%89%E9%94%AE%E5%80%BC%E5%AF%B9%E6%93%8D%E4%BD%9C/" class="post-title-link" itemprop="url">Spark入门之基础知识（三）键值对操作</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:33:21 / 修改时间：18:34:14" itemprop="dateCreated datePublished" datetime="2021-06-08T18:33:21+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="键值对RDD在实际生产中很常用，通常用来进行聚合计算，并且Spark对键值对RDD也提供了新的操作接口可以做更多操作，本文简单介绍一些键值对RDD的基础操作。"><a href="#键值对RDD在实际生产中很常用，通常用来进行聚合计算，并且Spark对键值对RDD也提供了新的操作接口可以做更多操作，本文简单介绍一些键值对RDD的基础操作。" class="headerlink" title="键值对RDD在实际生产中很常用，通常用来进行聚合计算，并且Spark对键值对RDD也提供了新的操作接口可以做更多操作，本文简单介绍一些键值对RDD的基础操作。"></a>键值对RDD在实际生产中很常用，通常用来进行聚合计算，并且Spark对键值对RDD也提供了新的操作接口可以做更多操作，本文简单介绍一些键值对RDD的基础操作。</h2><h3 id="如何创建Pair-RDD"><a href="#如何创建Pair-RDD" class="headerlink" title="如何创建Pair RDD"></a>如何创建Pair RDD</h3><p>1）键值对格式的数据可以直接读入，返回Pair RDD<br>2）使用map()把一个普通的RDD转化为Pair RDD<br>读取text文件，取每行文本的第一个单词做key，该行文本做value</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">val lines = context.textFile(&quot;text&quot;)</span><br><span class="line">lines.map(x =&gt; (x.split(&quot; &quot;)(0), x))</span><br></pre></td></tr></table></figure>

<h3 id="Pair-RDD的转化操作"><a href="#Pair-RDD的转化操作" class="headerlink" title="Pair RDD的转化操作"></a>Pair RDD的转化操作</h3><p>Pair RDD也是RDD，对RDD可用的操作对于Pair RDD也可用。</p>
<p>首先创建出一个Pair RDD</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;  val data = sc.parallelize(List(1,2,3,4,4))</span><br><span class="line">data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[7] at parallelize at &lt;console&gt;:24</span><br><span class="line"></span><br><span class="line">scala&gt; val data2 = data.map(x =&gt; (x,1))</span><br><span class="line">data2: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[8] at map at &lt;console&gt;:26</span><br><span class="line"></span><br><span class="line">scala&gt; data2.take(10)</span><br><span class="line">res16: Array[(Int, Int)] = Array((1,1), (2,1), (3,1), (4,1), (4,1))</span><br></pre></td></tr></table></figure>

<p>1)reduceByKey<br>合并具有相同键的值</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     val result1 = data2.reduceByKey((x, y) =&gt; x + y)</span><br><span class="line">result1: org.apache.spark.rdd.RDD[(Int, Int)] = ShuffledRDD[10] at reduceByKey at &lt;console&gt;:28</span><br><span class="line">scala&gt; result1.collect()</span><br><span class="line">res19: Array[(Int, Int)] = Array((4,2), (2,1), (1,1), (3,1))     </span><br></pre></td></tr></table></figure>

<p>2）groupByKey<br>对相同键的值进行分组</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     data2.groupByKey().collect()</span><br><span class="line">res20: Array[(Int, Iterable[Int])] = Array((4,CompactBuffer(1, 1)), (2,CompactBuffer(1)), (1,CompactBuffer(1)), (3,CompactBuffer(1)))</span><br></pre></td></tr></table></figure>

<p>3）mapValues<br>对Pair RDD中的每个值应用函数而不改变键</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     data2.mapValues(x =&gt; x * 10).collect()</span><br><span class="line">res21: Array[(Int, Int)] = Array((1,10), (2,10), (3,10), (4,10), (4,10))  </span><br></pre></td></tr></table></figure>

<p>4）flatMapValues<br>应用函数到键值对中的值上，每一个KV对的Value都会被映射成一系列的值，这些值再和K重新组合成多个KV对</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     data2.flatMapValues(x =&gt; x to (4)).collect()</span><br><span class="line">res22: Array[(Int, Int)] = Array((1,1), (1,2), (1,3), (1,4), (2,1), (2,2), (2,3), (2,4), (3,1), (3,2), (3,3), (3,4), (4,1), (4,2), (4,3), (4,4), (4,1), (4,2), (4,3), (4,4))</span><br></pre></td></tr></table></figure>

<p>5）keys<br>返回一个仅包含键值得RDD</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     data2.keys.collect()</span><br><span class="line">res23: Array[Int] = Array(1, 2, 3, 4, 4)      </span><br></pre></td></tr></table></figure>

<p>6）values<br>返回一个仅包含值得RDD</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     data2.values.collect()</span><br><span class="line">res24: Array[Int] = Array(1, 1, 1, 1, 1)</span><br></pre></td></tr></table></figure>

<p>7）sortByKey<br>返回一个根据键值排序的RDD（范围分区）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     data2.sortByKey().collect()</span><br><span class="line">res25: Array[(Int, Int)] = Array((1,1), (2,1), (3,1), (4,1), (4,1))</span><br></pre></td></tr></table></figure>

<p>8）combineByKey<br>基于键进行聚合的函数，对于分区中的每一个键值，要么是已经遍历过的，要么是还没遍历过的。</p>
<p>如果是已经遍历过的：<br>使用 mergeValue 进行处理</p>
<p>如果是还没遍历过的：<br>使用createCombiner进行处理</p>
<p>如果多个分区中都有同一个键值：<br>使用mergeCombiner进行处理</p>
<p>计算平均值的例子：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">val data = sc.parallelize(List(&quot;a&quot;, &quot;aa&quot;, &quot;aaa&quot;, &quot;aaa&quot;, &quot;aaaa&quot;))</span><br><span class="line">val pair = data.map(x =&gt; (x, x.length))</span><br><span class="line">val result = pair.combineByKey(</span><br><span class="line">// 对于每一个新出现的key ，保存对应的value值  同时将个数初始化为1</span><br><span class="line">  valueOfKey =&gt; (valueOfKey, 1),   </span><br><span class="line">//  对于已经出现过的key值，将新出现的key对应的value进行累加，同时个数加一</span><br><span class="line">  (tmp: (Int, Int), newValue) =&gt; (tmp._1 + newValue, tmp._2 + 1),  </span><br><span class="line">//  多个分区进行合并时，如果两个分区有相同的key值，则把两个分区统计完的总value进行相加，同时计算值的个数</span><br><span class="line">  (tmp1: (Int, Int), tmp2: (Int, Int)) =&gt; (tmp1._1 + tmp2._1, tmp1._2 + tmp2._2)  </span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; result.take(10)</span><br><span class="line">res5: Array[(String, (Int, Int))] = Array((aa,(2,1)), (aaaa,(4,1)), (a,(1,1)), (aaa,(6,2)))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">// 计算平均值</span><br><span class="line">    val avg = result.map&#123; case (key, value) =&gt; (key, value._1 / value._2.toFloat) &#125;</span><br><span class="line"></span><br><span class="line">scala&gt; avg.take(10)</span><br><span class="line">res6: Array[(String, Float)] = Array((aa,2.0), (aaaa,4.0), (a,1.0), (aaa,3.0))</span><br></pre></td></tr></table></figure>


<p>9）查看分区数</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;     val partitionSize = result.partitions.size</span><br><span class="line">partitionSize: Int = 2</span><br></pre></td></tr></table></figure>
<p>可以使用repartition或者coalesce进行重分区。</p>
<p>repartition和coalesce的区别：<br>repartition的底层实现为简单调用了coalesce，并将shuffle 设置为 true。<br>如果我们目前有1000个分区，想要重分区成100个，最好调用coalesce，因为整个过程不会发生shuffle。<br>如果我们有100个分区，想要重分区成1000个，这时候需要调用repartition，调用coalesce是无效的，因为不经过shuffle无法增加分区。</p>
<p>10）groupBy<br>对RDD中每个元素应用函数，函数的结果作为该元素的key，再根据key进行分组</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">val data3 = sc.parallelize(List(1,2,3,4,5,6))</span><br><span class="line">val data4 = data3.groupBy( x =&gt; (x%2))</span><br><span class="line">data4.take(10)</span><br><span class="line"></span><br><span class="line">res7: Array[(Int, Iterable[Int])] = Array((0,CompactBuffer(2, 4, 6)), (1,CompactBuffer(1, 3, 5)))</span><br></pre></td></tr></table></figure>
<p>在上面的代码中我们将奇数分为一组，偶数分为一组。</p>
<p>11）join连接操作</p>
<p>内连接</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">	val ori1 = sc.parallelize(List(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;d&quot;))</span><br><span class="line">    val first = ori1.map(x =&gt; (x,1))</span><br><span class="line">    val ori2 = sc.parallelize(List(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;e&quot;))</span><br><span class="line">    val second = ori2.map(x =&gt; (x,2))</span><br><span class="line">    val joinResult = first.join(second)</span><br><span class="line">    joinResult.take(10)</span><br><span class="line"></span><br><span class="line">res8: Array[(String, (Int, Int))] = Array((b,(1,2)), (a,(1,2)), (c,(1,2)))      </span><br></pre></td></tr></table></figure>

<p>左外连接（右外连接同理）</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">	val leftResult = first.leftOuterJoin(second)</span><br><span class="line">    leftResult.take(10)</span><br><span class="line"></span><br><span class="line">scala&gt;     leftResult.take(10)</span><br><span class="line">res9: Array[(String, (Int, Option[Int]))] = Array((d,(1,None)), (b,(1,Some(2))), (a,(1,Some(2))), (c,(1,Some(2))))</span><br></pre></td></tr></table></figure>


<p>join操作的执行过程：<br>默认情况下，连接操作会将两个数据集中所有键的哈希值都求出来，将哈希值相同的记录通过网络传输到同一台机器上，在该机器上对所有键相同的记录执行连接操作。</p>
<h3 id="Pair-RDD的行动操作"><a href="#Pair-RDD的行动操作" class="headerlink" title="Pair RDD的行动操作"></a>Pair RDD的行动操作</h3><p><img src="https://img-blog.csdnimg.cn/20191219171254168.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h6 id="Spark会为生成RDD设定好分区方式的操作"><a href="#Spark会为生成RDD设定好分区方式的操作" class="headerlink" title="Spark会为生成RDD设定好分区方式的操作"></a>Spark会为生成RDD设定好分区方式的操作</h6><p>cogroup<br>groupWith<br>join<br>leftOuterJoin<br>rightOuterJoin<br>groupByKey<br>reduceByKey<br>combineByKey<br>partitionBy<br>sort<br>mapValues<br>flatMapValues<br>filter</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B9%8B%E5%A6%82%E4%BD%95%E5%88%86%E5%B1%82/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93%E4%B9%8B%E5%A6%82%E4%BD%95%E5%88%86%E5%B1%82/" class="post-title-link" itemprop="url">数据仓库之如何分层</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:27:45 / 修改时间：18:32:52" itemprop="dateCreated datePublished" datetime="2021-06-08T18:27:45+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%95%B0%E6%8D%AE%E4%BB%93%E5%BA%93/" itemprop="url" rel="index"><span itemprop="name">数据仓库</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="1-前言"><a href="#1-前言" class="headerlink" title="1.前言"></a>1.前言</h1><p>数据仓库的建设是一个持续的工程。在这个过程中我们需要形成自己的规范，以方便管理和维护。在数据仓库的建设过程中，不仅会面临着公司业务迅速发展，业务系统迭代变更，需要对业务系统数据进行相应的整合，形成公司完整的统一数据视图；而且基于数据仓库的应用也是多样化的，比如支撑自己企业的数据可视化平台、即席查询、对策略提供数据支持等。参考目前已有的分层模型，结合自身实际数据情况，确定对数据仓库进行层次划分，不同的层次，承担不同的职责，方便模型的管理与维护。</p>
<h1 id="2-数仓模型"><a href="#2-数仓模型" class="headerlink" title="2.数仓模型"></a>2.数仓模型</h1><h3 id="2-1-数仓分层介绍"><a href="#2-1-数仓分层介绍" class="headerlink" title="2.1 数仓分层介绍"></a>2.1 数仓分层介绍</h3><table>
<thead>
<tr>
<th align="center">模型层次</th>
<th align="center">英文名称</th>
<th align="center">中文名称</th>
<th align="center">对应逻辑层</th>
<th align="center">存储数据</th>
</tr>
</thead>
<tbody><tr>
<td align="center">ODL</td>
<td align="center">Operational Data Layer</td>
<td align="center">操作数据层，原始数据层，日志层</td>
<td align="center">ods</td>
<td align="center">存储直接从业务系统或者日志系统接收的原始数据，只同步不做任何修改处理</td>
</tr>
<tr>
<td align="center">IDL</td>
<td align="center">Integrated Data Layer</td>
<td align="center">集成数据层，事实层，明细数据层</td>
<td align="center">dwd</td>
<td align="center">存放按照业务主题组织的事实数据，未补充维度，不做过度加工（不加分析的口径），保留原始事实</td>
</tr>
<tr>
<td align="center">CDL</td>
<td align="center">Component Data Layer</td>
<td align="center">元件数据层，（轻度）汇总层</td>
<td align="center">dws</td>
<td align="center">存放从dwd经过汇总或者跨业务主题的数据，以面向单个分析场景为主组织主题，可以引入指标口径</td>
</tr>
<tr>
<td align="center">MDL</td>
<td align="center">Mart Data Layer</td>
<td align="center">数据集市层，汇总宽表层</td>
<td align="center">dws</td>
<td align="center">存放从dwd,dws来源的多维度冗余的宽表，可面向多个分析场景组织</td>
</tr>
<tr>
<td align="center">ADL</td>
<td align="center">Application Data Layer</td>
<td align="center">应用数据层</td>
<td align="center">dm</td>
<td align="center">存放从dws,dwd来源的面向单个特定分析场景的灵活数据</td>
</tr>
<tr>
<td align="center">DIM</td>
<td align="center">Dimension Data Layer</td>
<td align="center">维度层</td>
<td align="center">dim</td>
<td align="center">存放维度数据</td>
</tr>
</tbody></table>
<h3 id="2-2-模型思想"><a href="#2-2-模型思想" class="headerlink" title="2.2 模型思想"></a>2.2 模型思想</h3><h5 id="ODL模型"><a href="#ODL模型" class="headerlink" title="ODL模型"></a><font color='yellow'>ODL模型</font></h5><p><em><strong>数据层次</strong></em></p>
<p>ODL（操作数据层），该层级主要临时存储从多种数据源（包括在线业务系统和点击流日志）抽取的业务数据。</p>
<p><em><strong>数据特点</strong></em></p>
<p>1.数据集结构及数据集间关系都和数据源基本保持一致</p>
<p>2.临时存储，数据存储一到两周即可删除或备份至廉价设备</p>
<p>3.数据集多为增量抽取，产生大量的Delta数据集</p>
<p><em><strong>数据处理</strong></em></p>
<p>1.数据集增量获取、分发</p>
<p>2.数据集轻度清洗，如字符集转换、脏数据过滤、第一类维值标准化处理等</p>
<p>3.点击流数据处理，完成日志获取、字符串处理、URL解析等</p>
<p><em><strong>数据抽取</strong></em></p>
<p>主要是增量抽取为主、有部分业务表涉及全量抽取；</p>
<p><em><strong>数据存储</strong></em></p>
<p>ODL层设计上分为两个层次，第一个层次存储近一段时间的增量数据（贴源）；</p>
<p>第二个层次存储全量数据信息，通过append delta表生成全量数据；</p>
<h5 id="IDL模型"><a href="#IDL模型" class="headerlink" title="IDL模型"></a><font color='yellow'>IDL模型</font></h5><p><em><strong>数据层次</strong></em></p>
<p>IDL（集成数据层），该层级按照业务主题组织数据，完成对ODL层数据的清洗和集成，为CDL层提供数据结构统一、业务语义标准的基础数据。</p>
<p><em><strong>数据特点</strong></em></p>
<p>1.明细数据，按照业务主题分类，以业务为驱动设计表结构和表间关系</p>
<p>2.数据集成，基于3NF设计模型，并在语义层达到统一和标准</p>
<p>3.数据带有仓库层的日期和状态标签，可追溯其生命周期中的所有变化状态</p>
<p><em><strong>数据处理</strong></em></p>
<p>1.对ODL数据进行集成整合，数据项进行重定义和清洗，完成业务数据的归一化处理</p>
<p>2.梳理第一类维表来源，即从源业务系统抽取的代码表，并完成缓慢变化维处理</p>
<p>3.使用ODL层的Delta（增、删、改）数据、全量数据更新当前表和历史表，数据存储上采用拉链和快照方式存储</p>
<p><em><strong>数据更新策略</strong></em></p>
<p>1.全量快照：每天存储一份最新的数据，来源数据为全量数据，且需要保留历史变化轨迹</p>
<p>2.拉链表：通过开闭链时间维护最新数据</p>
<p>3.增量表：增量插入当天分区，例如：日志表</p>
<p>4.全量覆盖：删除目标表全部数据，再插入当前数据；来源数据为全量数据，且无需保留历史轨迹，只使用最新状态数据</p>
<h5 id="CDL模型"><a href="#CDL模型" class="headerlink" title="CDL模型"></a><font color='yellow'>CDL模型</font></h5><p><em><strong>数据层次</strong></em></p>
<p>CDL（元件数据层），该层级按照分析主题组织数据，跨IDL层的业务主题，集成与该分析主题相关的所有数据，为ADL层的分析模型提供共享的、可复用的元件数据。</p>
<p><em><strong>数据特点</strong></em></p>
<p>1.数据模型相对稳定，无衍生指标，轻度汇总</p>
<p>2.多维模型：分析对象的状态（静态、描述）数据和相关事实表或维表关联形成以冗余宽表为中心的雪花或星型模型</p>
<p>3.基础指标库：分析对象的行为（主动、被动）数据汇总而成的一系列基础指标库</p>
<p><em><strong>数据处理</strong></em></p>
<p>1.分析对象和相关事实表或维表进行多表关联计算生成多维模型</p>
<p>2.对分析对象的行为数据进行汇总计算生成基础指标库</p>
<p>3.梳理两类维表来源，一是分析需求，二是仓库技术</p>
<p>4.对多维模型或基础指标数据进行轻度汇总，产生基础的、通用的汇总模型</p>
<p><em><strong>数据种类</strong></em></p>
<p>1.多维模型数据（Multidimensional Data）：采用维度建模方式建立的数据模型数据。</p>
<p>2.基础指标库数据(Stable Indicator Data)：基于某个分析实体的一系列基础指标集合。</p>
<p>3.常用通用的JOIN数据（Common Join Data）：从IDL层上来的一些实体对象，可能需要经常JOIN在一起使用，在此可以预先处理一些常用通用的JOIN逻辑。</p>
<p><em><strong>数据刷新</strong></em></p>
<p>保留每日数据的应用状态，存储采用每日数据快照的方式</p>
<h5 id="MDL模型"><a href="#MDL模型" class="headerlink" title="MDL模型"></a><font color='yellow'>MDL模型</font></h5><p><em><strong>数据层次</strong></em></p>
<p>MDL（数据集市层），该层次主要功能是加工多维度冗余的宽表（解决复杂的查询）、多角度分析的汇总表。</p>
<p><em><strong>数据特点</strong></em></p>
<p>1.数据模型相对稳定，有衍生指标</p>
<p>2.宽表模型：基础指标群、多维模型数据和相关事实表或维表关联形成通用或定制的冗余宽表</p>
<p>3.多角度汇总：从多个角度分析的汇总模型</p>
<p><em><strong>数据处理</strong></em></p>
<p>1.多维模型数据和相关事实表或维表进行多表关联计算生成宽表模型</p>
<p>2.对多维模型或基础指标数据进行汇总，产生个性的、通用的汇总模型</p>
<h5 id="ADL模型"><a href="#ADL模型" class="headerlink" title="ADL模型"></a><font color='yellow'>ADL模型</font></h5><p><em><strong>数据层次</strong></em></p>
<p>ADL（应用数据层），该层级按照项目和应用组织数据，以CDL层的半成品元件数据为基础，规划多样化、个性化的衍生指标体系、分析模型和数据应用。</p>
<p><em><strong>数据特点</strong></em></p>
<p>1.数据模型不稳定，随着分析算法和应用的变更随时变化或下线</p>
<p>2.数据高度汇总，可做交叉分析、上卷、下钻、切片、切块、旋转等多维分析操作</p>
<p>3.更高级的数据分析或挖掘应用，衍生出信息类、知识类数据</p>
<p><em><strong>数据处理</strong></em></p>
<p>1.根据不同的数据应用处理数据，所有的指标或者汇总都依赖于具体的业务分析主题和分析人员的定义，并直接交付信息给使用者</p>
<p>2.数据处理和信息交付方式多样，如报表、仪表盘、即席查询、多维分析、实时数据应用、数据挖掘应用等</p>
<h5 id="DIM模型"><a href="#DIM模型" class="headerlink" title="DIM模型"></a><font color='yellow'>DIM模型</font></h5><p>DIM层主要包括三类即简单、静态、代码类维表，存储仓库层归纳梳理的所有维表信息</p>
<p>1).从业务源系统抽取转化的维表，每日保留全量快照；</p>
<p>2).根据业务分析需求构建的维表，每日保留全量快照；</p>
<p>3).仓库技术常用维表，只保留当前信息；</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/Hadoop-NameNode-%E9%AB%98%E5%8F%AF%E7%94%A8-High-Availability-%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Hadoop-NameNode-%E9%AB%98%E5%8F%AF%E7%94%A8-High-Availability-%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/" class="post-title-link" itemprop="url">Hadoop NameNode 高可用 (High Availability) 实现解析</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:25:38 / 修改时间：18:27:16" itemprop="dateCreated datePublished" datetime="2021-06-08T18:25:38+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><a target="_blank" rel="noopener" href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html">原文链接</a></p>
<h1 id="NameNode-高可用整体架构概述"><a href="#NameNode-高可用整体架构概述" class="headerlink" title="NameNode 高可用整体架构概述"></a>NameNode 高可用整体架构概述</h1><p>在 Hadoop 1.0 时代，Hadoop 的两大核心组件 HDFS NameNode 和 JobTracker 都存在着单点问题，这其中以 NameNode 的单点问题尤为严重。因为 NameNode 保存了整个 HDFS 的元数据信息，一旦 NameNode 挂掉，整个 HDFS 就无法访问，同时 Hadoop 生态系统中依赖于 HDFS 的各个组件，包括 MapReduce、Hive、Pig 以及 HBase 等也都无法正常工作，并且重新启动 NameNode 和进行数据恢复的过程也会比较耗时。这些问题在给 Hadoop 的使用者带来困扰的同时，也极大地限制了 Hadoop 的使用场景，使得 Hadoop 在很长的时间内仅能用作离线存储和离线计算，无法应用到对可用性和数据一致性要求很高的在线应用场景中。</p>
<p>所幸的是，在 Hadoop2.0 中，HDFS NameNode 和 YARN ResourceManger(JobTracker 在 2.0 中已经被整合到 YARN ResourceManger 之中) 的单点问题都得到了解决，经过多个版本的迭代和发展，目前已经能用于生产环境。HDFS NameNode 和 YARN ResourceManger 的高可用 (High Availability，HA) 方案基本类似，两者也复用了部分代码，但是由于 HDFS NameNode 对于数据存储和数据一致性的要求比 YARN ResourceManger 高得多，所以 HDFS NameNode 的高可用实现更为复杂一些，本文从内部实现的角度对 HDFS NameNode 的高可用机制进行详细的分析。</p>
<p>HDFS NameNode 的高可用整体架构如图 1 所示 (图片来源于参考文献 [1])：<br>图 1.HDFS NameNode 高可用整体架构<br><img src="https://img-blog.csdnimg.cn/20200209113132878.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>从上图中，我们可以看出 NameNode 的高可用架构主要分为下面几个部分：</p>
<p>Active NameNode 和 Standby NameNode：两台 NameNode 形成互备，一台处于 Active 状态，为主 NameNode，另外一台处于 Standby 状态，为备 NameNode，只有主 NameNode 才能对外提供读写服务。</p>
<p>主备切换控制器 ZKFailoverController：ZKFailoverController 作为独立的进程运行，对 NameNode 的主备切换进行总体控制。ZKFailoverController 能及时检测到 NameNode 的健康状况，在主 NameNode 故障时借助 Zookeeper 实现自动的主备选举和切换，当然 NameNode 目前也支持不依赖于 Zookeeper 的手动主备切换。</p>
<p>Zookeeper 集群：为主备切换控制器提供主备选举支持。</p>
<p>共享存储系统：共享存储系统是实现 NameNode 的高可用最为关键的部分，共享存储系统保存了 NameNode 在运行过程中所产生的 HDFS 的元数据。主 NameNode 和</p>
<p>NameNode 通过共享存储系统实现元数据同步。在进行主备切换的时候，新的主 NameNode 在确认元数据完全同步之后才能继续对外提供服务。</p>
<p>DataNode 节点：除了通过共享存储系统共享 HDFS 的元数据信息之外，主 NameNode 和备 NameNode 还需要共享 HDFS 的数据块和 DataNode 之间的映射关系。DataNode 会同时向主 NameNode 和备 NameNode 上报数据块的位置信息。</p>
<p>下面开始分别介绍 NameNode 的主备切换实现和共享存储系统的实现，在文章的最后会结合笔者的实践介绍一下在 NameNode 的高可用运维中的一些注意事项。</p>
<h1 id="NameNode-的主备切换实现"><a href="#NameNode-的主备切换实现" class="headerlink" title="NameNode 的主备切换实现"></a>NameNode 的主备切换实现</h1><p>NameNode 主备切换主要由 ZKFailoverController、HealthMonitor 和 ActiveStandbyElector 这 3 个组件来协同实现：</p>
<p>ZKFailoverController 作为 NameNode 机器上一个独立的进程启动 (在 hdfs 启动脚本之中的进程名为 zkfc)，启动的时候会创建 HealthMonitor 和 ActiveStandbyElector 这两个主要的内部组件，ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，也会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调方法。</p>
<p>HealthMonitor 主要负责检测 NameNode 的健康状态，如果检测到 NameNode 的状态发生变化，会回调 ZKFailoverController 的相应方法进行自动的主备选举。</p>
<p>ActiveStandbyElector 主要负责完成自动的主备选举，内部封装了 Zookeeper 的处理逻辑，一旦 Zookeeper 主备选举完成，会回调 ZKFailoverController 的相应方法来进行 NameNode 的主备状态切换。</p>
<p>NameNode 实现主备切换的流程如图 2 所示，有以下几步：</p>
<p>1、HealthMonitor 初始化完成之后会启动内部的线程来定时调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法，对 NameNode 的健康状态进行检测。<br>2、HealthMonitor 如果检测到 NameNode 的健康状态发生变化，会回调ZKFailoverController 注册的相应方法进行处理。<br>3、如果 ZKFailoverController 判断需要进行主备切换，会首先使用 ActiveStandbyElector 来进行自动的主备选举。<br>4、ActiveStandbyElector 与 Zookeeper 进行交互完成自动的主备选举。<br>5、ActiveStandbyElector 在主备选举完成后，会回调 ZKFailoverController 的相应方法来通知当前的 NameNode 成为主 NameNode 或备 NameNode。<br>6、ZKFailoverController 调用对应 NameNode 的 HAServiceProtocol RPC 接口的方法将 NameNode 转换为 Active 状态或 Standby 状态。<br>图 2.NameNode 的主备切换流程</p>
<p><img src="https://img-blog.csdnimg.cn/20200209113344704.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>下面分别对 HealthMonitor、ActiveStandbyElector 和 ZKFailoverController 的实现细节进行分析：</p>
<h2 id="HealthMonitor-实现分析"><a href="#HealthMonitor-实现分析" class="headerlink" title="HealthMonitor 实现分析"></a>HealthMonitor 实现分析</h2><p>ZKFailoverController 在初始化的时候会创建 HealthMonitor，HealthMonitor 在内部会启动一个线程来循环调用 NameNode 的 HAServiceProtocol RPC 接口的方法来检测 NameNode 的状态，并将状态的变化通过回调的方式来通知 ZKFailoverController。</p>
<p>HealthMonitor 主要检测 NameNode 的两类状态，分别是 HealthMonitor.State 和 HAServiceStatus。HealthMonitor.State 是通过 HAServiceProtocol RPC 接口的 monitorHealth 方法来获取的，反映了 NameNode 节点的健康状况，主要是磁盘存储资源是否充足。HealthMonitor.State 包括下面几种状态：</p>
<ol>
<li>INITIALIZING：HealthMonitor 在初始化过程中，还没有开始进行健康状况检测；</li>
<li>SERVICE_HEALTHY：NameNode 状态正常；</li>
<li>SERVICE_NOT_RESPONDING：调用 NameNode 的 monitorHealth 方法调用无响应或响应超时；</li>
<li>SERVICE_UNHEALTHY：NameNode 还在运行，但是 monitorHealth 方法返回状态不正常，磁盘存储资源不足；</li>
<li>HEALTH_MONITOR_FAILED：HealthMonitor 自己在运行过程中发生了异常，不能继续检测 NameNode 的健康状况，会导致 ZKFailoverController 进程退出；</li>
</ol>
<p>HealthMonitor.State 在状态检测之中起主要的作用，在 HealthMonitor.State 发生变化的时候，HealthMonitor 会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<p>而 HAServiceStatus 则是通过 HAServiceProtocol RPC 接口的 getServiceStatus 方法来获取的，主要反映的是 NameNode 的 HA 状态，包括：</p>
<ol>
<li>INITIALIZING：NameNode 在初始化过程中；</li>
<li>ACTIVE：当前 NameNode 为主 NameNode；</li>
<li>STANDBY：当前 NameNode 为备 NameNode；</li>
<li>STOPPING：当前 NameNode 已停止；</li>
</ol>
<p>HAServiceStatus 在状态检测之中只是起辅助的作用，在 HAServiceStatus 发生变化时，HealthMonitor 也会回调 ZKFailoverController 的相应方法来进行处理，具体处理见后文 ZKFailoverController 部分所述。</p>
<h2 id="ActiveStandbyElector-实现分析"><a href="#ActiveStandbyElector-实现分析" class="headerlink" title="ActiveStandbyElector 实现分析"></a>ActiveStandbyElector 实现分析</h2><p>Namenode(包括 YARN ResourceManager) 的主备选举是通过 ActiveStandbyElector 来完成的，ActiveStandbyElector 主要是利用了 Zookeeper 的写一致性和临时节点机制，具体的主备选举实现如下：</p>
<h4 id="创建锁节点"><a href="#创建锁节点" class="headerlink" title="创建锁节点"></a>创建锁节点</h4><p>如果 HealthMonitor 检测到对应的 NameNode 的状态正常，那么表示这个 NameNode 有资格参加 Zookeeper 的主备选举。如果目前还没有进行过主备选举的话，那么相应的 ActiveStandbyElector 就会发起一次主备选举，尝试在 Zookeeper 上创建一个路径为/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 的临时节点 (${dfs.nameservices} 为 Hadoop 的配置参数 dfs.nameservices 的值，下同)，Zookeeper 的写一致性会保证最终只会有一个 ActiveStandbyElector 创建成功，那么创建成功的 ActiveStandbyElector 对应的 NameNode 就会成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Active 状态。而创建失败的 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的方法进一步将对应的 NameNode 切换为 Standby 状态。</p>
<h4 id="注册-Watcher-监听"><a href="#注册-Watcher-监听" class="headerlink" title="注册 Watcher 监听"></a>注册 Watcher 监听</h4><p>不管创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点是否成功，ActiveStandbyElector 随后都会向 Zookeeper 注册一个 Watcher 来监听这个节点的状态变化事件，ActiveStandbyElector 主要关注这个节点的 NodeDeleted 事件。</p>
<h4 id="自动触发主备选举"><a href="#自动触发主备选举" class="headerlink" title="自动触发主备选举"></a>自动触发主备选举</h4><p>如果 Active NameNode 对应的 HealthMonitor 检测到 NameNode 的状态异常时， ZKFailoverController 会主动删除当前在 Zookeeper 上建立的临时节点/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock，这样处于 Standby 状态的 NameNode 的 ActiveStandbyElector 注册的监听器就会收到这个节点的 NodeDeleted 事件。收到这个事件之后，会马上再次进入到创建/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点的流程，如果创建成功，这个本来处于 Standby 状态的 NameNode 就选举为主 NameNode 并随后开始切换为 Active 状态。</p>
<p>当然，如果是 Active 状态的 NameNode 所在的机器整个宕掉的话，那么根据 Zookeeper 的临时节点特性，/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 节点会自动被删除，从而也会自动进行一次主备切换。</p>
<p>ActiveStandbyElector 为了实现 fencing，会在成功创建 Zookeeper 节点 hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 从而成为 Active NameNode 之后，创建另外一个路径为/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 的持久节点，这个节点里面保存了这个 Active NameNode 的地址信息。Active NameNode 的 ActiveStandbyElector 在正常的状态下关闭 Zookeeper Session 的时候 (注意由于/hadoop-ha/${dfs.nameservices}/ActiveStandbyElectorLock 是临时节点，也会随之删除)，会一起删除节点/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb。但是如果 ActiveStandbyElector 在异常的状态下 Zookeeper Session 关闭 (比如前述的 Zookeeper 假死)，那么由于/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 是持久节点，会一直保留下来。后面当另一个 NameNode 选主成功之后，会注意到上一个 Active NameNode 遗留下来的这个节点，从而会回调 ZKFailoverController 的方法对旧的 Active NameNode 进行 fencing，具体处理见后文 ZKFailoverController 部分所述。</p>
<h4 id="防止脑裂"><a href="#防止脑裂" class="headerlink" title="防止脑裂"></a>防止脑裂</h4><p>Zookeeper 在工程实践的过程中经常会发生的一个现象就是 Zookeeper 客户端“假死”，所谓的“假死”是指如果 Zookeeper 客户端机器负载过高或者正在进行 JVM Full GC，那么可能会导致 Zookeeper 客户端到 Zookeeper 服务端的心跳不能正常发出，一旦这个时间持续较长，超过了配置的 Zookeeper Session Timeout 参数的话，Zookeeper 服务端就会认为客户端的 session 已经过期从而将客户端的 Session 关闭。“假死”有可能引起分布式系统常说的双主或脑裂 (brain-split) 现象。具体到本文所述的 NameNode，假设 NameNode1 当前为 Active 状态，NameNode2 当前为 Standby 状态。如果某一时刻 NameNode1 对应的 ZKFailoverController 进程发生了“假死”现象，那么 Zookeeper 服务端会认为 NameNode1 挂掉了，根据前面的主备切换逻辑，NameNode2 会替代 NameNode1 进入 Active 状态。但是此时 NameNode1 可能仍然处于 Active 状态正常运行，即使随后 NameNode1 对应的 ZKFailoverController 因为负载下降或者 Full GC 结束而恢复了正常，感知到自己和 Zookeeper 的 Session 已经关闭，但是由于网络的延迟以及 CPU 线程调度的不确定性，仍然有可能会在接下来的一段时间窗口内 NameNode1 认为自己还是处于 Active 状态。这样 NameNode1 和 NameNode2 都处于 Active 状态，都可以对外提供服务。这种情况对于 NameNode 这类对数据一致性要求非常高的系统来说是灾难性的，数据会发生错乱且无法恢复。Zookeeper 社区对这种问题的解决方法叫做 fencing，中文翻译为隔离，也就是想办法把旧的 Active NameNode 隔离起来，使它不能正常对外提供服务。</p>
<h2 id="ZKFailoverController-实现分析"><a href="#ZKFailoverController-实现分析" class="headerlink" title="ZKFailoverController 实现分析"></a>ZKFailoverController 实现分析</h2><p>ZKFailoverController 在创建 HealthMonitor 和 ActiveStandbyElector 的同时，会向 HealthMonitor 和 ActiveStandbyElector 注册相应的回调函数，ZKFailoverController 的处理逻辑主要靠 HealthMonitor 和 ActiveStandbyElector 的回调函数来驱动。</p>
<h4 id="对-HealthMonitor-状态变化的处理"><a href="#对-HealthMonitor-状态变化的处理" class="headerlink" title="对 HealthMonitor 状态变化的处理"></a>对 HealthMonitor 状态变化的处理</h4><p>如前所述，HealthMonitor 会检测 NameNode 的两类状态，HealthMonitor.State 在状态检测之中起主要的作用，ZKFailoverController 注册到 HealthMonitor 上的处理 HealthMonitor.State 状态变化的回调函数主要关注 SERVICE_HEALTHY、SERVICE_NOT_RESPONDING 和 SERVICE_UNHEALTHY 这 3 种状态：</p>
<ol>
<li>如果检测到状态为 SERVICE_HEALTHY，表示当前的 NameNode 有资格参加 Zookeeper 的主备选举，如果目前还没有进行过主备选举的话，ZKFailoverController 会调用 ActiveStandbyElector 的 joinElection 方法发起一次主备选举。</li>
<li>如果检测到状态为 SERVICE_NOT_RESPONDING 或者是 SERVICE_UNHEALTHY，就表示当前的 NameNode 出现问题了，ZKFailoverController 会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举，这样其它的 NameNode 就有机会成为主 NameNode。</li>
</ol>
<p>而 HAServiceStatus 在状态检测之中仅起辅助的作用，在 HAServiceStatus 发生变化时，ZKFailoverController 注册到 HealthMonitor 上的处理 HAServiceStatus 状态变化的回调函数会判断 NameNode 返回的 HAServiceStatus 和 ZKFailoverController 所期望的是否一致，如果不一致的话，ZKFailoverController 也会调用 ActiveStandbyElector 的 quitElection 方法删除当前已经在 Zookeeper 上建立的临时节点退出主备选举。</p>
<h4 id="对-ActiveStandbyElector-主备选举状态变化的处理"><a href="#对-ActiveStandbyElector-主备选举状态变化的处理" class="headerlink" title="对 ActiveStandbyElector 主备选举状态变化的处理"></a>对 ActiveStandbyElector 主备选举状态变化的处理</h4><p>在 ActiveStandbyElector 的主备选举状态发生变化时，会回调 ZKFailoverController 注册的回调函数来进行相应的处理：</p>
<ol>
<li>如果 ActiveStandbyElector 选主成功，那么 ActiveStandbyElector 对应的 NameNode 成为主 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeActive 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToActive 方法，将 NameNode 转换为 Active 状态。</li>
<li>如果 ActiveStandbyElector 选主失败，那么 ActiveStandbyElector 对应的 NameNode 成为备 NameNode，ActiveStandbyElector 会回调 ZKFailoverController 的 becomeStandby 方法，这个方法通过调用对应的 NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，将 NameNode 转换为 Standby 状态。</li>
<li>如果 ActiveStandbyElector 选主成功之后，发现了上一个 Active NameNode 遗留下来的/hadoop-ha/${dfs.nameservices}/ActiveBreadCrumb 节点 (见“ActiveStandbyElector 实现分析”一节“防止脑裂”部分所述)，那么 ActiveStandbyElector 会首先回调 ZKFailoverController 注册的 fenceOldActive 方法，尝试对旧的 Active NameNode 进行 fencing，在进行 fencing 的时候，会执行以下的操作：</li>
</ol>
<p>首先尝试调用这个旧 Active NameNode 的 HAServiceProtocol RPC 接口的 transitionToStandby 方法，看能不能把它转换为 Standby 状态。<br>如果 transitionToStandby 方法调用失败，那么就执行 Hadoop 配置文件之中预定义的隔离措施，Hadoop 目前主要提供两种隔离措施，通常会选择 sshfence：</p>
<p>sshfence：通过 SSH 登录到目标机器上，执行命令 fuser 将对应的进程杀死；<br>shellfence：执行一个用户自定义的 shell 脚本来将对应的进程隔离；</p>
<p>只有在成功地执行完成 fencing 之后，选主成功的 ActiveStandbyElector 才会回调 ZKFailoverController 的 becomeActive 方法将对应的 NameNode 转换为 Active 状态，开始对外提供服务。</p>
<h1 id="NameNode-的共享存储实现"><a href="#NameNode-的共享存储实现" class="headerlink" title="NameNode 的共享存储实现"></a>NameNode 的共享存储实现</h1><p>过去几年中 Hadoop 社区涌现过很多的 NameNode 共享存储方案，比如 shared NAS+NFS、BookKeeper、BackupNode 和 QJM(Quorum Journal Manager) 等等。目前社区已经把由 Clouderea 公司实现的基于 QJM 的方案合并到 HDFS 的 trunk 之中并且作为默认的共享存储实现，本部分只针对基于 QJM 的共享存储方案的内部实现原理进行分析。为了理解 QJM 的设计和实现，首先要对 NameNode 的元数据存储结构有所了解。</p>
<h4 id="NameNode-的元数据存储概述"><a href="#NameNode-的元数据存储概述" class="headerlink" title="NameNode 的元数据存储概述"></a>NameNode 的元数据存储概述</h4><p>一个典型的 NameNode 的元数据存储目录结构如图 3 所示 (图片来源于参考文献 [4])，这里主要关注其中的 EditLog 文件和 FSImage 文件：</p>
<p>图 3 .NameNode 的元数据存储目录结构<br><img src="https://img-blog.csdnimg.cn/20200209114111102.png" alt="在这里插入图片描述"></p>
<p>NameNode 在执行 HDFS 客户端提交的创建文件或者移动文件这样的写操作的时候，会首先把这些操作记录在 EditLog 文件之中，然后再更新内存中的文件系统镜像。内存中的文件系统镜像用于 NameNode 向客户端提供读服务，而 EditLog 仅仅只是在数据恢复的时候起作用。记录在 EditLog 之中的每一个操作又称为一个事务，每个事务有一个整数形式的事务 id 作为编号。EditLog 会被切割为很多段，每一段称为一个 Segment。正在写入的 EditLog Segment 处于 in-progress 状态，其文件名形如 edits_inprogress_${start_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，例如上图中的 edits_inprogress_0000000000000000020。而已经写入完成的 EditLog Segment 处于 finalized 状态，其文件名形如 edits_${start_txid}-${end_txid}，其中${start_txid} 表示这个 segment 的起始事务 id，${end_txid} 表示这个 segment 的结束事务 id，例如上图中的 edits_0000000000000000001-0000000000000000019。</p>
<p>NameNode 会定期对内存中的文件系统镜像进行 checkpoint 操作，在磁盘上生成 FSImage 文件，FSImage 文件的文件名形如 fsimage_${end_txid}，其中${end_txid} 表示这个 fsimage 文件的结束事务 id，例如上图中的 fsimage_0000000000000000020。在 NameNode 启动的时候会进行数据恢复，首先把 FSImage 文件加载到内存中形成文件系统镜像，然后再把 EditLog 之中 FsImage 的结束事务 id 之后的 EditLog 回放到这个文件系统镜像上。</p>
<h4 id="基于-QJM-的共享存储系统的总体架构"><a href="#基于-QJM-的共享存储系统的总体架构" class="headerlink" title="基于 QJM 的共享存储系统的总体架构"></a>基于 QJM 的共享存储系统的总体架构</h4><p>基于 QJM 的共享存储系统主要用于保存 EditLog，并不保存 FSImage 文件。FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 (参见参考文献 [3])，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。每个 JournalNode 保存同样的 EditLog 副本。每次 NameNode 写 EditLog 的时候，除了向本地磁盘写入 EditLog 之外，也会并行地向 JournalNode 集群之中的每一个 JournalNode 发送写请求，只要大多数 (majority) 的 JournalNode 节点返回成功就认为向 JournalNode 集群写入 EditLog 成功。如果有 2N+1 台 JournalNode，那么根据大多数的原则，最多可以容忍有 N 台 JournalNode 节点挂掉。</p>
<p>基于 QJM 的共享存储系统的内部实现架构图如图 4 所示，主要包含下面几个主要的组件：</p>
<p>图 4 . 基于 QJM 的共享存储系统的内部实现架构图</p>
<p><img src="https://img-blog.csdnimg.cn/20200209114154714.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>FSEditLog：这个类封装了对 EditLog 的所有操作，是 NameNode 对 EditLog 的所有操作的入口。</p>
<p>JournalSet： 这个类封装了对本地磁盘和 JournalNode 集群上的 EditLog 的操作，内部包含了两类 JournalManager，一类为 FileJournalManager，用于实现对本地磁盘上 EditLog 的操作。一类为 QuorumJournalManager，用于实现对 JournalNode 集群上共享目录的 EditLog 的操作。FSEditLog 只会调用 JournalSet 的相关方法，而不会直接使用 FileJournalManager 和 QuorumJournalManager。</p>
<p>FileJournalManager：封装了对本地磁盘上的 EditLog 文件的操作，不仅 NameNode 在向本地磁盘上写入 EditLog 的时候使用 FileJournalManager，JournalNode 在向本地磁盘写入 EditLog 的时候也复用了 FileJournalManager 的代码和逻辑。</p>
<p>QuorumJournalManager：封装了对 JournalNode 集群上的 EditLog 的操作，它会根据 JournalNode 集群的 URI 创建负责与 JournalNode 集群通信的类 AsyncLoggerSet， QuorumJournalManager 通过 AsyncLoggerSet 来实现对 JournalNode 集群上的 EditLog 的写操作，对于读操作，QuorumJournalManager 则是通过 Http 接口从 JournalNode 上的 JournalNodeHttpServer 读取 EditLog 的数据。</p>
<p>AsyncLoggerSet：内部包含了与 JournalNode 集群进行通信的 AsyncLogger 列表，每一个 AsyncLogger 对应于一个 JournalNode 节点，另外 AsyncLoggerSet 也包含了用于等待大多数 JournalNode 返回结果的工具类方法给 QuorumJournalManager 使用。</p>
<p>AsyncLogger：具体的实现类是 IPCLoggerChannel，IPCLoggerChannel 在执行方法调用的时候，会把调用提交到一个单线程的线程池之中，由线程池线程来负责向对应的 JournalNode 的 JournalNodeRpcServer 发送 RPC 请求。</p>
<p>JournalNodeRpcServer：运行在 JournalNode 节点进程中的 RPC 服务，接收 NameNode 端的 AsyncLogger 的 RPC 请求。</p>
<p>JournalNodeHttpServer：运行在 JournalNode 节点进程中的 Http 服务，用于接收处于 Standby 状态的 NameNode 和其它 JournalNode 的同步 EditLog 文件流的请求。</p>
<p>下面对基于 QJM 的共享存储系统的两个关键性问题同步数据和恢复数据进行详细分析。</p>
<h4 id="基于-QJM-的共享存储系统的数据同步机制分析"><a href="#基于-QJM-的共享存储系统的数据同步机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据同步机制分析"></a>基于 QJM 的共享存储系统的数据同步机制分析</h4><p>Active NameNode 和 StandbyNameNode 使用 JouranlNode 集群来进行数据同步的过程如图 5 所示，Active NameNode 首先把 EditLog 提交到 JournalNode 集群，然后 Standby NameNode 再从 JournalNode 集群定时同步 EditLog：</p>
<p>图 5 . 基于 QJM 的共享存储的数据同步机制</p>
<p><img src="https://img-blog.csdnimg.cn/20200209114225733.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h6 id="Active-NameNode-提交-EditLog-到-JournalNode-集群"><a href="#Active-NameNode-提交-EditLog-到-JournalNode-集群" class="headerlink" title="Active NameNode 提交 EditLog 到 JournalNode 集群"></a>Active NameNode 提交 EditLog 到 JournalNode 集群</h6><p>当处于 Active 状态的 NameNode 调用 FSEditLog 类的 logSync 方法来提交 EditLog 的时候，会通过 JouranlSet 同时向本地磁盘目录和 JournalNode 集群上的共享存储目录写入 EditLog。写入 JournalNode 集群是通过并行调用每一个 JournalNode 的 QJournalProtocol RPC 接口的 journal 方法实现的，如果对大多数 JournalNode 的 journal 方法调用成功，那么就认为提交 EditLog 成功，否则 NameNode 就会认为这次提交 EditLog 失败。提交 EditLog 失败会导致 Active NameNode 关闭 JournalSet 之后退出进程，留待处于 Standby 状态的 NameNode 接管之后进行数据恢复。</p>
<p>从上面的叙述可以看出，Active NameNode 提交 EditLog 到 JournalNode 集群的过程实际上是同步阻塞的，但是并不需要所有的 JournalNode 都调用成功，只要大多数 JournalNode 调用成功就可以了。如果无法形成大多数，那么就认为提交 EditLog 失败，NameNode 停止服务退出进程。如果对应到分布式系统的 CAP 理论的话，虽然采用了 Paxos 的“大多数”思想对 C(consistency，一致性) 和 A(availability，可用性) 进行了折衷，但还是可以认为 NameNode 选择了 C 而放弃了 A，这也符合 NameNode 对数据一致性的要求。</p>
<h6 id="Standby-NameNode-从-JournalNode-集群同步-EditLog"><a href="#Standby-NameNode-从-JournalNode-集群同步-EditLog" class="headerlink" title="Standby NameNode 从 JournalNode 集群同步 EditLog"></a>Standby NameNode 从 JournalNode 集群同步 EditLog</h6><p>当 NameNode 进入 Standby 状态之后，会启动一个 EditLogTailer 线程。这个线程会定期调用 EditLogTailer 类的 doTailEdits 方法从 JournalNode 集群上同步 EditLog，然后把同步的 EditLog 回放到内存之中的文件系统镜像上 (并不会同时把 EditLog 写入到本地磁盘上)。</p>
<p>这里需要关注的是：从 JournalNode 集群上同步的 EditLog 都是处于 finalized 状态的 EditLog Segment。“NameNode 的元数据存储概述”一节说过 EditLog Segment 实际上有两种状态，处于 in-progress 状态的 Edit Log 当前正在被写入，被认为是处于不稳定的中间态，有可能会在后续的过程之中发生修改，比如被截断。Active NameNode 在完成一个 EditLog Segment 的写入之后，就会向 JournalNode 集群发送 finalizeLogSegment RPC 请求，将完成写入的 EditLog Segment finalized，然后开始下一个新的 EditLog Segment。一旦 finalizeLogSegment 方法在大多数的 JournalNode 上调用成功，表明这个 EditLog Segment 已经在大多数的 JournalNode 上达成一致。一个 EditLog Segment 处于 finalized 状态之后，可以保证它再也不会变化。</p>
<p>从上面描述的过程可以看出，虽然 Active NameNode 向 JournalNode 集群提交 EditLog 是同步的，但 Standby NameNode 采用的是定时从 JournalNode 集群上同步 EditLog 的方式，那么 Standby NameNode 内存中文件系统镜像有很大的可能是落后于 Active NameNode 的，所以 Standby NameNode 在转换为 Active NameNode 的时候需要把落后的 EditLog 补上来。</p>
<h4 id="基于-QJM-的共享存储系统的数据恢复机制分析"><a href="#基于-QJM-的共享存储系统的数据恢复机制分析" class="headerlink" title="基于 QJM 的共享存储系统的数据恢复机制分析"></a>基于 QJM 的共享存储系统的数据恢复机制分析</h4><p>处于 Standby 状态的 NameNode 转换为 Active 状态的时候，有可能上一个 Active NameNode 发生了异常退出，那么 JournalNode 集群中各个 JournalNode 上的 EditLog 就可能会处于不一致的状态，所以首先要做的事情就是让 JournalNode 集群中各个节点上的 EditLog 恢复为一致。另外如前所述，当前处于 Standby 状态的 NameNode 的内存中的文件系统镜像有很大的可能是落后于旧的 Active NameNode 的，所以在 JournalNode 集群中各个节点上的 EditLog 达成一致之后，接下来要做的事情就是从 JournalNode 集群上补齐落后的 EditLog。只有在这两步完成之后，当前新的 Active NameNode 才能安全地对外提供服务。</p>
<p>补齐落后的 EditLog 的过程复用了前面描述的 Standby NameNode 从 JournalNode 集群同步 EditLog 的逻辑和代码，最终调用 EditLogTailer 类的 doTailEdits 方法来完成 EditLog 的补齐。使 JournalNode 集群上的 EditLog 达成一致的过程是一致性算法 Paxos 的典型应用场景，QJM 对这部分的处理可以看做是 Single Instance Paxos(参见参考文献 [3]) 算法的一个实现，在达成一致的过程中，Active NameNode 和 JournalNode 集群之间的交互流程如图 6 所示，具体描述如下：</p>
<p>图 6.Active NameNode 和 JournalNode 集群的交互流程图</p>
<p><img src="https://img-blog.csdnimg.cn/20200209114323734.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>生成一个新的 Epoch</p>
<p>Epoch 是一个单调递增的整数，用来标识每一次 Active NameNode 的生命周期，每发生一次 NameNode 的主备切换，Epoch 就会加 1。这实际上是一种 fencing 机制，为什么需要 fencing 已经在前面“ActiveStandbyElector 实现分析”一节的“防止脑裂”部分进行了说明。产生新 Epoch 的流程与 Zookeeper 的 ZAB(Zookeeper Atomic Broadcast) 协议在进行数据恢复之前产生新 Epoch 的过程完全类似：</p>
<ol>
<li><p>Active NameNode 首先向 JournalNode 集群发送 getJournalState RPC 请求，每个 JournalNode 会返回自己保存的最近的那个 Epoch(代码中叫 lastPromisedEpoch)。</p>
</li>
<li><p>NameNode 收到大多数的 JournalNode 返回的 Epoch 之后，在其中选择最大的一个加 1 作为当前的新 Epoch，然后向各个 JournalNode 发送 newEpoch RPC 请求，把这个新的 Epoch 发给各个 JournalNode。</p>
</li>
<li><p>每一个 JournalNode 在收到新的 Epoch 之后，首先检查这个新的 Epoch 是否比它本地保存的 lastPromisedEpoch 大，如果大的话就把 lastPromisedEpoch 更新为这个新的 Epoch，并且向 NameNode 返回它自己的本地磁盘上最新的一个 EditLogSegment 的起始事务 id，为后面的数据恢复过程做好准备。如果小于或等于的话就向 NameNode 返回错误。</p>
</li>
<li><p>NameNode 收到大多数 JournalNode 对 newEpoch 的成功响应之后，就会认为生成新的 Epoch 成功。</p>
</li>
</ol>
<p>在生成新的 Epoch 之后，每次 NameNode 在向 JournalNode 集群提交 EditLog 的时候，都会把这个 Epoch 作为参数传递过去。每个 JournalNode 会比较传过来的 Epoch 和它自己保存的 lastPromisedEpoch 的大小，如果传过来的 epoch 的值比它自己保存的 lastPromisedEpoch 小的话，那么这次写相关操作会被拒绝。一旦大多数 JournalNode 都拒绝了这次写操作，那么这次写操作就失败了。如果原来的 Active NameNode 恢复正常之后再向 JournalNode 写 EditLog，那么因为它的 Epoch 肯定比新生成的 Epoch 小，并且大多数的 JournalNode 都接受了这个新生成的 Epoch，所以拒绝写入的 JournalNode 数目至少是大多数，这样原来的 Active NameNode 写 EditLog 就肯定会失败，失败之后这个 NameNode 进程会直接退出，这样就实现了对原来的 Active NameNode 的隔离了。</p>
<h6 id="选择需要数据恢复的-EditLog-Segment-的-id"><a href="#选择需要数据恢复的-EditLog-Segment-的-id" class="headerlink" title="选择需要数据恢复的 EditLog Segment 的 id"></a>选择需要数据恢复的 EditLog Segment 的 id</h6><p>需要恢复的 Edit Log 只可能是各个 JournalNode 上的最后一个 Edit Log Segment，如前所述，JournalNode 在处理完 newEpoch RPC 请求之后，会向 NameNode 返回它自己的本地磁盘上最新的一个 EditLog Segment 的起始事务 id，这个起始事务 id 实际上也作为这个 EditLog Segment 的 id。NameNode 会在所有这些 id 之中选择一个最大的 id 作为要进行数据恢复的 EditLog Segment 的 id。</p>
<h6 id="向-JournalNode-集群发送-prepareRecovery-RPC-请求"><a href="#向-JournalNode-集群发送-prepareRecovery-RPC-请求" class="headerlink" title="向 JournalNode 集群发送 prepareRecovery RPC 请求"></a>向 JournalNode 集群发送 prepareRecovery RPC 请求</h6><p>NameNode 接下来向 JournalNode 集群发送 prepareRecovery RPC 请求，请求的参数就是选出的 EditLog Segment 的 id。JournalNode 收到请求后返回本地磁盘上这个 Segment 的起始事务 id、结束事务 id 和状态 (in-progress 或 finalized)。</p>
<p>这一步对应于 Paxos 算法的 Phase 1a 和 Phase 1b(参见参考文献 [3]) 两步。Paxos 算法的 Phase1 是 prepare 阶段，这也与方法名 prepareRecovery 相对应。并且这里以前面产生的新的 Epoch 作为 Paxos 算法中的提案编号 (proposal number)。只要大多数的 JournalNode 的 prepareRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<p>选择进行同步的基准数据源，向 JournalNode 集群发送 acceptRecovery RPC 请求 NameNode 根据 prepareRecovery 的返回结果，选择一个 JournalNode 上的 EditLog Segment 作为同步的基准数据源。选择基准数据源的原则大致是：在 in-progress 状态和 finalized 状态的 Segment 之间优先选择 finalized 状态的 Segment。如果都是 in-progress 状态的话，那么优先选择 Epoch 比较高的 Segment(也就是优先选择更新的)，如果 Epoch 也一样，那么优先选择包含的事务数更多的 Segment。</p>
<p>在选定了同步的基准数据源之后，NameNode 向 JournalNode 集群发送 acceptRecovery RPC 请求，将选定的基准数据源作为参数。JournalNode 接收到 acceptRecovery RPC 请求之后，从基准数据源 JournalNode 的 JournalNodeHttpServer 上下载 EditLog Segment，将本地的 EditLog Segment 替换为下载的 EditLog Segment。</p>
<p>这一步对应于 Paxos 算法的 Phase 2a 和 Phase 2b(参见参考文献 [3]) 两步。Paxos 算法的 Phase2 是 accept 阶段，这也与方法名 acceptRecovery 相对应。只要大多数 JournalNode 的 acceptRecovery RPC 调用成功返回，NameNode 就认为成功。</p>
<h6 id="向-JournalNode-集群发送-finalizeLogSegment-RPC-请求，数据恢复完成"><a href="#向-JournalNode-集群发送-finalizeLogSegment-RPC-请求，数据恢复完成" class="headerlink" title="向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成"></a>向 JournalNode 集群发送 finalizeLogSegment RPC 请求，数据恢复完成</h6><p>上一步执行完成之后，NameNode 确认大多数 JournalNode 上的 EditLog Segment 已经从基准数据源进行了同步。接下来，NameNode 向 JournalNode 集群发送 finalizeLogSegment RPC 请求，JournalNode 接收到请求之后，将对应的 EditLog Segment 从 in-progress 状态转换为 finalized 状态，实际上就是将文件名从 edits_inprogress_${startTxid} 重命名为 edits_${startTxid}-${endTxid}，见“NameNode 的元数据存储概述”一节的描述。</p>
<p>只要大多数 JournalNode 的 finalizeLogSegment RPC 调用成功返回，NameNode 就认为成功。此时可以保证 JournalNode 集群的大多数节点上的 EditLog 已经处于一致的状态，这样 NameNode 才能安全地从 JournalNode 集群上补齐落后的 EditLog 数据。</p>
<p>需要注意的是，尽管基于 QJM 的共享存储方案看起来理论完备，设计精巧，但是仍然无法保证数据的绝对强一致，下面选取参考文献 [2] 中的一个例子来说明：</p>
<p>假设有 3 个 JournalNode：JN1、JN2 和 JN3，Active NameNode 发送了事务 id 为 151、152 和 153 的 3 个事务到 JournalNode 集群，这 3 个事务成功地写入了 JN2，但是在还没能写入 JN1 和 JN3 之前，Active NameNode 就宕机了。同时，JN3 在整个写入的过程中延迟较大，落后于 JN1 和 JN2。最终成功写入 JN1 的事务 id 为 150，成功写入 JN2 的事务 id 为 153，而写入到 JN3 的事务 id 仅为 125，如图 7 所示 (图片来源于参考文献 [2])。按照前面描述的只有成功地写入了大多数的 JournalNode 才认为写入成功的原则，显然事务 id 为 151、152 和 153 的这 3 个事务只能算作写入失败。在进行数据恢复的过程中，会发生下面两种情况：</p>
<p>图 7.JournalNode 集群写入的事务 id 情况</p>
<p><img src="https://img-blog.csdnimg.cn/20200209114457736.png" alt="在这里插入图片描述"></p>
<p>如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段收到了 JN2 的回复，那么肯定会以 JN2 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 153。从恢复的结果来看，实际上可以认为前面宕机的 Active NameNode 对事务 id 为 151、152 和 153 的这 3 个事务的写入成功了。但是如果从 NameNode 自身的角度来看，这显然就发生了数据不一致的情况。<br>如果随后的 Active NameNode 进行数据恢复时在 prepareRecovery 阶段没有收到 JN2 的回复，那么肯定会以 JN1 对应的 EditLog Segment 为基准来进行数据恢复，这样最后在多数 JournalNode 上的 EditLog Segment 会恢复到事务 150。在这种情况下，如果从 NameNode 自身的角度来看的话，数据就是一致的了。</p>
<p>事实上不光本文描述的基于 QJM 的共享存储方案无法保证数据的绝对一致，大家通常认为的一致性程度非常高的 Zookeeper 也会发生类似的情况，这也从侧面说明了要实现一个数据绝对一致的分布式存储系统的确非常困难。</p>
<h4 id="NameNode-在进行状态转换时对共享存储的处理"><a href="#NameNode-在进行状态转换时对共享存储的处理" class="headerlink" title="NameNode 在进行状态转换时对共享存储的处理"></a>NameNode 在进行状态转换时对共享存储的处理</h4><p>下面对 NameNode 在进行状态转换的过程中对共享存储的处理进行描述，使得大家对基于 QJM 的共享存储方案有一个完整的了解，同时也作为本部分的总结。</p>
<h6 id="NameNode-初始化启动，进入-Standby-状态"><a href="#NameNode-初始化启动，进入-Standby-状态" class="headerlink" title="NameNode 初始化启动，进入 Standby 状态"></a>NameNode 初始化启动，进入 Standby 状态</h6><p>在 NameNode 以 HA 模式启动的时候，NameNode 会认为自己处于 Standby 模式，在 NameNode 的构造函数中会加载 FSImage 文件和 EditLog Segment 文件来恢复自己的内存文件系统镜像。在加载 EditLog Segment 的时候，调用 FSEditLog 类的 initSharedJournalsForRead 方法来创建只包含了在 JournalNode 集群上的共享目录的 JournalSet，也就是说，这个时候只会从 JournalNode 集群之中加载 EditLog，而不会加载本地磁盘上的 EditLog。另外值得注意的是，加载的 EditLog Segment 只是处于 finalized 状态的 EditLog Segment，而处于 in-progress 状态的 Segment 需要后续在切换为 Active 状态的时候，进行一次数据恢复过程，将 in-progress 状态的 Segment 转换为 finalized 状态的 Segment 之后再进行读取。</p>
<p>加载完 FSImage 文件和共享目录上的 EditLog Segment 文件之后，NameNode 会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，正式进入 Standby 模式。如前所述，EditLogTailer 线程的作用是定时从 JournalNode 集群上同步 EditLog。而 StandbyCheckpointer 线程的作用其实是为了替代 Hadoop 1.x 版本之中的 Secondary NameNode 的功能，StandbyCheckpointer 线程会在 Standby NameNode 节点上定期进行 Checkpoint，将 Checkpoint 之后的 FSImage 文件上传到 Active NameNode 节点。</p>
<h6 id="NameNode-从-Standby-状态切换为-Active-状态"><a href="#NameNode-从-Standby-状态切换为-Active-状态" class="headerlink" title="NameNode 从 Standby 状态切换为 Active 状态"></a>NameNode 从 Standby 状态切换为 Active 状态</h6><p>当 NameNode 从 Standby 状态切换为 Active 状态的时候，首先需要做的就是停止它在 Standby 状态的时候启动的线程和相关的服务，包括上面提到的 EditLogTailer 线程和 StandbyCheckpointer 线程，然后关闭用于读取 JournalNode 集群的共享目录上的 EditLog 的 JournalSet，接下来会调用 FSEditLog 的 initJournalSetForWrite 方法重新打开 JournalSet。不同的是，这个 JournalSet 内部同时包含了本地磁盘目录和 JournalNode 集群上的共享目录。这些工作完成之后，就开始执行“基于 QJM 的共享存储系统的数据恢复机制分析”一节所描述的流程，调用 FSEditLog 类的 recoverUnclosedStreams 方法让 JournalNode 集群中各个节点上的 EditLog 达成一致。然后调用 EditLogTailer 类的 catchupDuringFailover 方法从 JournalNode 集群上补齐落后的 EditLog。最后打开一个新的 EditLog Segment 用于新写入数据，同时启动 Active NameNode 所需要的线程和服务。</p>
<h6 id="NameNode-从-Active-状态切换为-Standby-状态"><a href="#NameNode-从-Active-状态切换为-Standby-状态" class="headerlink" title="NameNode 从 Active 状态切换为 Standby 状态"></a>NameNode 从 Active 状态切换为 Standby 状态</h6><p>当 NameNode 从 Active 状态切换为 Standby 状态的时候，首先需要做的就是停止它在 Active 状态的时候启动的线程和服务，然后关闭用于读取本地磁盘目录和 JournalNode 集群上的共享目录的 EditLog 的 JournalSet。接下来会调用 FSEditLog 的 initSharedJournalsForRead 方法重新打开用于读取 JournalNode 集群上的共享目录的 JournalSet。这些工作完成之后，就会启动 EditLogTailer 线程和 StandbyCheckpointer 线程，EditLogTailer 线程会定时从 JournalNode 集群上同步 Edit Log。</p>
<h1 id="NameNode-高可用运维中的注意事项"><a href="#NameNode-高可用运维中的注意事项" class="headerlink" title="NameNode 高可用运维中的注意事项"></a>NameNode 高可用运维中的注意事项</h1><p>本节结合笔者的实践，从初始化部署和日常运维两个方面介绍一些在 NameNode 高可用运维中的注意事项。</p>
<h4 id="初始化部署"><a href="#初始化部署" class="headerlink" title="初始化部署"></a>初始化部署</h4><p>如果在开始部署 Hadoop 集群的时候就启用 NameNode 的高可用的话，那么相对会比较容易。但是如果在采用传统的单 NameNode 的架构运行了一段时间之后，升级为 NameNode 的高可用架构的话，就要特别注意在升级的时候需要按照以下的步骤进行操作：</p>
<ol>
<li>对 Zookeeper 进行初始化，创建 Zookeeper 上的/hadoop-ha/${dfs.nameservices} 节点。创建节点是为随后通过 Zookeeper 进行主备选举做好准备，在进行主备选举的时候会在这个节点下面创建子节点 (具体可参照“ActiveStandbyElector 实现分析”一节的叙述)。这一步通过在原有的 NameNode 上执行命令 hdfs zkfc -formatZK 来完成。</li>
<li>启动所有的 JournalNode，这通过脚本命令 hadoop-daemon.sh start journalnode 来完成。</li>
<li>对 JouranlNode 集群的共享存储目录进行格式化，并且将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件 (具体可参照“NameNode 的元数据存储概述”一节的叙述) 之后的 EditLog 拷贝到 JournalNode 集群上的共享目录之中，这通过在原有的 NameNode 上执行命令 hdfs namenode -initializeSharedEdits 来完成。</li>
<li>启动原有的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>对新增的 NameNode 节点进行初始化，将原有的 NameNode 本地磁盘上最近一次 checkpoint 操作生成 FSImage 文件拷贝到这个新增的 NameNode 的本地磁盘上，同时需要验证 JournalNode 集群的共享存储目录上已经具有了这个 FSImage 文件之后的 EditLog(已经在第 3 步完成了)。这一步通过在新增的 NameNode 上执行命令 hdfs namenode -bootstrapStandby 来完成。</li>
<li>启动新增的 NameNode 节点，这通过脚本命令 hadoop-daemon.sh start namenode 完成。</li>
<li>在这两个 NameNode 上启动 zkfc(ZKFailoverController) 进程，谁通过 Zookeeper 选主成功，谁就是主 NameNode，另一个为备 NameNode。这通过脚本命令 hadoop-daemon.sh start zkfc 完成。</li>
</ol>
<h4 id="日常维护"><a href="#日常维护" class="headerlink" title="日常维护"></a>日常维护</h4><p>笔者在日常的维护之中主要遇到过下面两种问题：</p>
<p>Zookeeper 过于敏感：Hadoop 的配置项中 Zookeeper 的 session timeout 的配置参数 ha.zookeeper.session-timeout.ms 的默认值为 5000，也就是 5s，这个值比较小，会导致 Zookeeper 比较敏感，可以把这个值尽量设置得大一些，避免因为网络抖动等原因引起 NameNode 进行无谓的主备切换。</p>
<p>单台 JouranlNode 故障时会导致主备无法切换：在理论上，如果有 3 台或者更多的 JournalNode，那么挂掉一台 JouranlNode 应该仍然可以进行正常的主备切换。但是笔者在某次 NameNode 重启的时候，正好赶上一台 JournalNode 挂掉宕机了，这个时候虽然某一台 NameNode 通过 Zookeeper 选主成功，但是这台被选为主的 NameNode 无法成功地从 Standby 状态切换为 Active 状态。事后追查原因发现，被选为主的 NameNode 卡在退出 Standby 状态的最后一步，这个时候它需要等待到 JournalNode 的请求全部完成之后才能退出。但是由于有一台 JouranlNode 宕机，到这台 JournalNode 的请求都积压在一起并且在不断地进行重试，同时在 Hadoop 的配置项中重试次数的默认值非常大，所以就会导致被选为主的 NameNode 无法及时退出 Standby 状态。这个问题主要是 Hadoop 内部的 RPC 通信框架的设计缺陷引起的，Hadoop HA 的源代码 IPCLoggerChannel 类中有关于这个问题的 TODO，但是截止到社区发布的 2.7.1 版本这个问题仍然存在。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%8F%8AJava%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%EF%BC%88GC%E7%AE%97%E6%B3%95%E3%80%81GC%E6%94%B6%E9%9B%86%E5%99%A8%EF%BC%89/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/JVM%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%8F%8AJava%E5%9E%83%E5%9C%BE%E6%94%B6%E9%9B%86%EF%BC%88GC%E7%AE%97%E6%B3%95%E3%80%81GC%E6%94%B6%E9%9B%86%E5%99%A8%EF%BC%89/" class="post-title-link" itemprop="url">JVM内存结构及Java垃圾收集（GC算法、GC收集器）</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:22:24 / 修改时间：18:25:06" itemprop="dateCreated datePublished" datetime="2021-06-08T18:22:24+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>最近正在复习Java相关的知识，总结一下JVM相关的知识点。</p>
<h1 id="JVM内存结构"><a href="#JVM内存结构" class="headerlink" title="JVM内存结构"></a>JVM内存结构</h1><p>先上图<br><img src="https://img-blog.csdnimg.cn/20200219111728915.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h4 id="堆内存（线程间共享）"><a href="#堆内存（线程间共享）" class="headerlink" title="堆内存（线程间共享）"></a>堆内存（线程间共享）</h4><p>在虚拟机启动时创建，此内存区域的唯一目的就是存放对象实例，是垃圾收集器管理的主要区域（也叫GC堆），Java堆可以处于物理上不连续的内存空间中，只要逻辑上是连续的即可，如果在堆中没有内存完成实例分配，并且堆也无法再扩展时（通过-Xmx和-Xms控制扩展），将会抛出OutOfMemoryError异常。</p>
<h4 id="方法区（线程间共享）（因为GC较少也叫永久代）"><a href="#方法区（线程间共享）（因为GC较少也叫永久代）" class="headerlink" title="方法区（线程间共享）（因为GC较少也叫永久代）"></a>方法区（线程间共享）（因为GC较少也叫永久代）</h4><p>用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。不需要连续的内存和可以选择固定大小或者可扩展，还可以选择不实现垃圾收集，这个区域的内存回收目标主要是针对常量池的回收和对类型的卸载，当方法区无法满足内存分配需求时，将抛出OutOfMemoryError异常。 </p>
<h4 id="虚拟机栈（线程私有）"><a href="#虚拟机栈（线程私有）" class="headerlink" title="虚拟机栈（线程私有）"></a>虚拟机栈（线程私有）</h4><p>生命周期与线程相同。描述的是Java方法执行的内存模型，每个方法被执行的时候都会同时创建一个栈帧（Stack Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。<br>如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；虚拟机动态扩展时无法申请到足够的内存时OOM</p>
<h4 id="本地方法栈（线程私有）"><a href="#本地方法栈（线程私有）" class="headerlink" title="本地方法栈（线程私有）"></a>本地方法栈（线程私有）</h4><p>类似于虚拟机栈，虚拟机栈为虚拟机执行Java方法服务，而本地方法栈则是为虚拟机使用到的Native方法服务，与虚拟机栈一样，本地方法栈区域也会抛出StackOverflowError和OutOfMemoryError异常。</p>
<h4 id="程序计数器（线程私有）"><a href="#程序计数器（线程私有）" class="headerlink" title="程序计数器（线程私有）"></a>程序计数器（线程私有）</h4><p>当前线程所执行的字节码的行号指示器。如果线程正在执行的是一个Java方法，这个计数器记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是Natvie方法，这个计数器值则为空（Undefined）。</p>
<p>字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，由于Java虚拟机的多线程是通过线程轮流切换并分配处理器执行时间的方式来实现的，在任何一个确定的时刻，一个处理器只会执行一条线程中的指令。因此，为了线程切换后能恢复到正确的执行位置，每条线程都需要有一个独立的程序计数器。此区域是唯一一个不会OOM的区域。</p>
<h4 id="如何通过参数控制各个区域的大小"><a href="#如何通过参数控制各个区域的大小" class="headerlink" title="如何通过参数控制各个区域的大小"></a>如何通过参数控制各个区域的大小</h4><p><img src="https://img-blog.csdnimg.cn/20200219112104266.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h1 id="Java的垃圾收集"><a href="#Java的垃圾收集" class="headerlink" title="Java的垃圾收集"></a>Java的垃圾收集</h1><h4 id="如何判断对象是否存活"><a href="#如何判断对象是否存活" class="headerlink" title="如何判断对象是否存活"></a>如何判断对象是否存活</h4><ol>
<li>引用计数<br>每个对象有一个引用计数属性，新增一个引用时计数加1，引用释放时计数减1，计数为0时可以回收，但是无法解决循环引用的问题。</li>
<li>可达性分析<br>从GC Roots开始向下搜索，搜索所走过的路径称为引用链。当一个对象到GC Roots没有任何引用链相连时，则证明此对象是不可用的。<br>GC Roots包括：<br>虚拟机栈中引用的对象；<br>方法区中类静态属性实体引用的对象；<br>方法区中常量引用的对象；<br>本地方法栈中JNI引用的对象。</li>
</ol>
<h4 id="垃圾回收算法"><a href="#垃圾回收算法" class="headerlink" title="垃圾回收算法"></a>垃圾回收算法</h4><h6 id="标记-—-清除算法"><a href="#标记-—-清除算法" class="headerlink" title="标记 — 清除算法"></a>标记 — 清除算法</h6><p>算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，在标记完成后统一回收掉所有被标记的对象。<br><img src="https://img-blog.csdnimg.cn/20200219112558756.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="
"><br>主要问题：<br>1、效率较低<br>2、会产生大量不连续的内存碎片，可能导致当程序在以后的运行过程中需要分配较大对象时，虽然总的空间足够，但是连续的内存空间却不足，不得不提前触发另一次垃圾收集动作。</p>
<h6 id="复制算法"><a href="#复制算法" class="headerlink" title="复制算法"></a>复制算法</h6><p>将可用内存按容量划分为大小相等的两块，每次只使用其中的一块。当这一块的内存用完了，就将还存活着的对象复制到另外一块上面，然后再把已使用过的内存空间一次清理掉。<br><img src="https://img-blog.csdnimg.cn/20200219112825305.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>主要问题：<br>虽然解决了内存碎片的问题，但是可用内存却减小了一半。<br>在实际应用中，因为多数对象都是很快就会被垃圾收集的，所以把整个内存区域分成了一个Eden区，两个survivor区，大小比为8:1：1，当回收时，将一个Eden区和一个survivor区活着的对象复制到另一个survivor区，再将这次的Eden和survivor区清理。</p>
<h6 id="标记-—-整理"><a href="#标记-—-整理" class="headerlink" title="标记 — 整理"></a>标记 — 整理</h6><p>标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理掉端边界以外的内存。<br><img src="https://img-blog.csdnimg.cn/2020021911335743.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h6 id="分代收集"><a href="#分代收集" class="headerlink" title="分代收集"></a>分代收集</h6><p>把Java堆分为新生代和老年代，对各代分别用适当的算法，新生代采用复制算法，老年代采用标记清除或标记整理算法。</p>
<h4 id="垃圾回收器"><a href="#垃圾回收器" class="headerlink" title="垃圾回收器"></a>垃圾回收器</h4><h6 id="Serial"><a href="#Serial" class="headerlink" title="Serial"></a>Serial</h6><ol>
<li>串行收集器，收集时stop the world，单线程收集器；</li>
<li>默认的client模式下的新生代收集器；</li>
<li>新生代复制，老年代标记整理，简单高效<br><img src="https://img-blog.csdnimg.cn/20200219113821725.png" alt="在这里插入图片描述"></li>
</ol>
<h6 id="ParNew"><a href="#ParNew" class="headerlink" title="ParNew"></a>ParNew</h6><ol>
<li>Serial收集器的多线程版本，新生代并行，老年代串行，收集时stop the world，server模式下默认的新生代收集器，能搭配CMS；</li>
<li>新生代复制算法、老年代标记-整理；</li>
<li>CPU好的环境里，停顿时间好于serial，并发能力差的环境里不如serial；<br><img src="https://img-blog.csdnimg.cn/202002191141021.png" alt="在这里插入图片描述"><h6 id="Parallel-Scavenge"><a href="#Parallel-Scavenge" class="headerlink" title="Parallel Scavenge"></a>Parallel Scavenge</h6></li>
<li>类似ParNew收集器，Parallel收集器更关注系统的<font color='yellow'>吞吐量</font>，适合在后台运算不需要太多交互的任务。</li>
<li>新生代复制算法、老年代标记-整理</li>
<li>可以设置GC最大停顿时间，具有自适应调节策略，以达到最大吞吐量<br><img src="https://img-blog.csdnimg.cn/20200219114309545.png" alt="在这里插入图片描述"></li>
</ol>
<h6 id="CMS"><a href="#CMS" class="headerlink" title="CMS"></a>CMS</h6><p>以获取<font color='yellow'>最短回收停顿时间</font>为目标的收集器，系统停顿时间最短，给用户带来较好的体验，基于标记—清除，具体过程为：</p>
<ol>
<li>初始标记：stop the world，仅仅只是标记一下GC Roots能直接关联到的对象，速度很快</li>
<li>并发标记（耗时最长）：进行GC Roots Tracing的过程，收集器线程与用户线程一起工作</li>
<li>重新标记：stop the world，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，时间比初始标记阶段稍长一些，但远比并发标记的时间短。 </li>
<li>并发清除（耗时最长）：并发回收垃圾，收集器线程与用户线程一起工作<br><img src="https://img-blog.csdnimg.cn/2020021912050944.png" alt="在这里插入图片描述"><br>整个过程中耗时最长的并发标记和并发清除过程中，收集器线程都可以与用户线程一起工作，但是并发阶段应用程序变慢，降低吞吐量，产生大量空间碎片，也无法处理浮动垃圾（并发清除时产生的垃圾，只能等到下次清除）</li>
</ol>
<h6 id="G1"><a href="#G1" class="headerlink" title="G1"></a>G1</h6><ol>
<li>面向<font color='yellow'>服务端</font>应用的垃圾收集器，整体看基于标记整理算法，局部看基于复制（两个region之间），不会产生内存空间碎片</li>
<li>可预测停顿，能让使用者明确指定在一个长度为N毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒</li>
<li>使用G1收集器时，Java堆的内存布局与其他收集器有很大差别，它将整个Java堆划分为多个大小相等的独立区域（Region），新生代和老年代不再是物理隔阂了，它们都是一部分（可以不连续）Region的集合。G1跟踪各个region中垃圾堆积的价值大小（回收空间及所需时间），在后台维护一个优先列表，在每次被允许的时间内，优先回收高价值的。</li>
</ol>
<p>回收过程分如下阶段：</p>
<ol>
<li>初始标记：stop the world，仅仅只是标记一下GC Roots能直接关联到的对象</li>
<li>并发标记：进行GC Roots Tracing的过程（进行可达性分析），可与用户程序并发执行</li>
<li>最终标记：stop the world，为了修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录，并行执行</li>
<li>筛选回收：对各个region回收价值和成本排序，制定回收计划。</li>
</ol>
<h4 id="什么时候进行Minor-GC（新生代GC）"><a href="#什么时候进行Minor-GC（新生代GC）" class="headerlink" title="什么时候进行Minor GC（新生代GC）"></a>什么时候进行Minor GC（新生代GC）</h4><p>Eden区没有足够的空间时</p>
<h4 id="什么时候进行Full-GC（Major-GC）"><a href="#什么时候进行Full-GC（Major-GC）" class="headerlink" title="什么时候进行Full GC（Major GC）"></a>什么时候进行Full GC（Major GC）</h4><p>只要老年代的连续空间 &gt; 新生代对象总大小  或  历次晋升的平均大小，就Minor GC，否则进行Full GC </p>
<h4 id="对象什么时候进入老年代"><a href="#对象什么时候进入老年代" class="headerlink" title="对象什么时候进入老年代"></a>对象什么时候进入老年代</h4><ol>
<li>大对象直接进入老年代，避免在Eden区和两个survivor区之间进行大量内存复制</li>
<li>长期存活的对象进入老年代，Eden区出生，Minor GC后进入Survivor区，年龄为1，之后每过一次Minor GC，年龄+1，到15岁进入老年代</li>
<li>Survivor空间中年龄相同的所有对象内存大小之和&gt;survivor空间的一半，大于等于该年龄的对象进入老年代</li>
<li>空间分配担保，复制算法时，8：1：1 比例下，存活的对象大小超过survivor区时，通过老年代进行担保</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/Spark%E7%AE%97%E5%AD%90%E4%B9%8BfoldByKey/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Spark%E7%AE%97%E5%AD%90%E4%B9%8BfoldByKey/" class="post-title-link" itemprop="url">Spark算子之foldByKey</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:19:25 / 修改时间：18:20:31" itemprop="dateCreated datePublished" datetime="2021-06-08T18:19:25+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Spark/" itemprop="url" rel="index"><span itemprop="name">Spark</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>在学习foldByKey这个算子的时候，发现网上好多文章的内容相互冲突，于是决定自己实践一边，以理解这个算子是怎么运行的。</p>
<h2 id="foldByKey"><a href="#foldByKey" class="headerlink" title="foldByKey"></a>foldByKey</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">foldByKey</span><span class="params">(zeroValue: V, numPartitions: Int)</span><span class="params">(func: (V, V)</span> </span>=&gt; V): RDD[(K, V)] = self.withScope &#123;</span><br><span class="line">    foldByKey(zeroValue, <span class="keyword">new</span> HashPartitioner(numPartitions))(func)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">foldByKey</span><span class="params">(zeroValue: V)</span><span class="params">(func: (V, V)</span> </span>=&gt; V): RDD[(K, V)] = self.withScope &#123;</span><br><span class="line">    foldByKey(zeroValue, defaultPartitioner(self))(func)</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<p>这是源码中对foldByKey的定义，主要是zeroValue这个点容易造成误解：</p>
<p>我们先初始化一个RDD</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd = sc.makeRDD(Array((<span class="string">&quot;A&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;A&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;B&quot;</span>,<span class="number">1</span>),(<span class="string">&quot;B&quot;</span>,<span class="number">2</span>),(<span class="string">&quot;C&quot;</span>,<span class="number">1</span>)))</span><br><span class="line">rdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[<span class="number">6</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br></pre></td></tr></table></figure>
<p>查看这个RDD的分区及分区中的元素</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd.mapPartitionsWithIndex((index, iter) =&gt; &#123;</span><br><span class="line">     |       <span class="keyword">var</span> rddmap = scala.collection.mutable.Map[String, List[(String, Int)]]()</span><br><span class="line">     |       <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">     |         <span class="keyword">var</span> elem = iter.next()</span><br><span class="line">     |         <span class="keyword">var</span> partNum = index + <span class="string">&quot;_&quot;</span></span><br><span class="line">     |         <span class="keyword">if</span> (rddmap.contains(partNum)) &#123;</span><br><span class="line">     |           <span class="keyword">var</span> elems = rddmap(partNum)</span><br><span class="line">     |           elems ::= elem</span><br><span class="line">     |           rddmap(partNum) = elems</span><br><span class="line">     |         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     |           <span class="keyword">var</span> newlist = List[(String,Int)]()</span><br><span class="line">     |           newlist ::= elem</span><br><span class="line">     |           rddmap(partNum) = newlist</span><br><span class="line">     |         &#125;</span><br><span class="line">     |       &#125;</span><br><span class="line">     |       rddmap.toIterator</span><br><span class="line">     |     &#125;).collect()</span><br><span class="line">res11: Array[(String, List[(String, Int)])] = Array((0_,List((A,<span class="number">2</span>), (A,<span class="number">1</span>))), (1_,List((C,<span class="number">1</span>), (B,<span class="number">2</span>), (B,<span class="number">1</span>))))</span><br></pre></td></tr></table></figure>
<p>可以看到，目前是有两个分区：<br>第一个分区中包含(A,2), (A,1)；<br>第二个分区中包含(C,1), (B,2), (B,1)</p>
<p>这时候我们用foldByKey算子，zeroValue设为2</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt;  rdd.foldByKey(<span class="number">2</span>) &#123; (x1, x2) =&gt; x1 + x2 &#125;.collect()</span><br><span class="line">res12: Array[(String, Int)] = Array((B,<span class="number">5</span>), (A,<span class="number">5</span>), (C,<span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<h4 id="再来看看另一种情况"><a href="#再来看看另一种情况" class="headerlink" title="再来看看另一种情况"></a>再来看看另一种情况</h4><p>在初始化RDD的过程中，将分区数设为3</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; <span class="keyword">var</span> rdd = sc.makeRDD(Array((<span class="string">&quot;A&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;A&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;B&quot;</span>, <span class="number">1</span>), (<span class="string">&quot;B&quot;</span>, <span class="number">2</span>), (<span class="string">&quot;C&quot;</span>, <span class="number">1</span>)),<span class="number">3</span>)</span><br><span class="line">rdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[<span class="number">11</span>] at makeRDD at &lt;console&gt;:<span class="number">24</span></span><br></pre></td></tr></table></figure>
<p>再查看下每个分区中的元素</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd.mapPartitionsWithIndex((index, iter) =&gt; &#123;</span><br><span class="line">     |       <span class="keyword">var</span> rddmap = scala.collection.mutable.Map[String, List[(String, Int)]]()</span><br><span class="line">     |       <span class="keyword">while</span> (iter.hasNext) &#123;</span><br><span class="line">     |         <span class="keyword">var</span> elem = iter.next()</span><br><span class="line">     |         <span class="keyword">var</span> partNum = index + <span class="string">&quot;_&quot;</span></span><br><span class="line">     |         <span class="keyword">if</span> (rddmap.contains(partNum)) &#123;</span><br><span class="line">     |           <span class="keyword">var</span> elems = rddmap(partNum)</span><br><span class="line">     |           elems ::= elem</span><br><span class="line">     |           rddmap(partNum) = elems</span><br><span class="line">     |         &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">     |           <span class="keyword">var</span> newlist = List[(String,Int)]()</span><br><span class="line">     |           newlist ::= elem</span><br><span class="line">     |           rddmap(partNum) = newlist</span><br><span class="line">     |         &#125;</span><br><span class="line">     |       &#125;</span><br><span class="line">     |       rddmap.toIterator</span><br><span class="line">     |     &#125;).collect()</span><br><span class="line">res13: Array[(String, List[(String, Int)])] = Array((0_,List((A,<span class="number">1</span>))), (1_,List((B,<span class="number">1</span>), (A,<span class="number">2</span>))), (2_,List((C,<span class="number">1</span>), (B,<span class="number">2</span>))))</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>第一个分区中只有 （A，1）<br>第二个分区中有 （B，1）（A，2）<br>第三个分区中有 （C，1）（B，2）<br>这时我们再使用foldByKey算子，zeroValue还是设为2</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">scala&gt; rdd.foldByKey(<span class="number">2</span>) &#123; (x1, x2) =&gt; x1 + x2 &#125;.collect()</span><br><span class="line">res14: Array[(String, Int)] = Array((B,<span class="number">7</span>), (C,<span class="number">3</span>), (A,<span class="number">7</span>))</span><br></pre></td></tr></table></figure>


<h6 id="出现了和第一次不一样的结果"><a href="#出现了和第一次不一样的结果" class="headerlink" title="出现了和第一次不一样的结果"></a>出现了和第一次不一样的结果</h6><p>由此我们已经可以推断出foldByKey的机制了，我的理解是：<br>取RDD的每一个分片，在每一个分片中，先根据你定义的映射，用zeroValue对不同key对应的value做<font color='yellow'>一次</font>初始化，再对剩下的value值做映射。</p>
<p>在第一次操作中，第一个分区中包含(A,2), (A,1)，先做初始化 2+2 = 4 ，再对剩下的值做累加， 最后得到 （A，4+1 = 5）</p>
<p>在第二次操作中，第一个分区中只有 （A，1），初始化为（A，2+1 = 3），第二个分区中有 （B，1）（A，2），因为是不同分区，所以也对A进行初始化（A，2+2 = 4），最后两个分区的结果统计到一起就是（A，4+3 = 7），BC同理。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/Hive%E4%B8%AD%E7%9A%84Skew-Join/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Hive%E4%B8%AD%E7%9A%84Skew-Join/" class="post-title-link" itemprop="url">Hive中的Skew Join</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 18:16:45 / 修改时间：18:18:05" itemprop="dateCreated datePublished" datetime="2021-06-08T18:16:45+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hive/" itemprop="url" rel="index"><span itemprop="name">Hive</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>看文档的时候突然发现Skew Join，之前只知道有内外连接，半开连接，全外连接，笛卡尔积，于是赶紧学习了下Skew Join，在这里做个总结。</p>
<h2 id="首先简单介绍下什么是数据倾斜"><a href="#首先简单介绍下什么是数据倾斜" class="headerlink" title="首先简单介绍下什么是数据倾斜"></a>首先简单介绍下什么是数据倾斜</h2><p>比如我们有10000条数据，有10个reducer来处理数据，在这10000条数据中有9000条的key是相同的，这样经过hash之后，就会出现有一个reducer要自己处理9000条数据，而剩下的9个reducer可能每个只处理100多条数据，当这9个reducer早早跑完之后，第一个reducer可能只完成了百分之几，这9个reducer就要静静等待…直到第一个完成，具体的表现就是任务一直卡在98% 99%，大大减慢了数据的处理速度。</p>
<h2 id="Skew-Join-是如何处理数据倾斜的"><a href="#Skew-Join-是如何处理数据倾斜的" class="headerlink" title="Skew Join 是如何处理数据倾斜的"></a>Skew Join 是如何处理数据倾斜的</h2><p>当我们开启Skew Join之后：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">set hive.optimize.skewjoin = true;</span><br></pre></td></tr></table></figure>
<p>在运行时，会对数据进行扫描并检测哪个key会出现倾斜，对于会倾斜的key，用map join做处理，不倾斜的key正常处理。</p>
<h5 id="举个栗子"><a href="#举个栗子" class="headerlink" title="举个栗子"></a>举个栗子</h5><p>表 A 和表 B join，并且在 ID 为12345 时发生了数据倾斜，假设在表 B 中倾斜的数据量比表 A 少，则把 B 中所有的倾斜了的数据拿出来，存到内存中（可以用一个哈希表来存）。<br>对于表 A ，如果是倾斜的数据，则通过 B 存放在内存中的哈希表来 join；如果不是倾斜的 key，则按正常的 reduce 端 join 流程进行。<br>这样就在map端完成了倾斜数据的处理，不会让某一个reducer中数据量爆炸，从而拖累处理速度。</p>
<p>要查看语句是否用到了 Skew Join，可以 explain 一下你的 SQL，如果在 Join Operator 和 Reduce Operator Tree 下的 handleSkewJoin 为 true，那就是用了Skew Join啦。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/%E8%AF%A6%E8%A7%A3TCP-IP%E5%8D%8F%E8%AE%AE%E6%A0%88/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/%E8%AF%A6%E8%A7%A3TCP-IP%E5%8D%8F%E8%AE%AE%E6%A0%88/" class="post-title-link" itemprop="url">详解TCP/IP协议栈</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 17:21:05 / 修改时间：18:07:14" itemprop="dateCreated datePublished" datetime="2021-06-08T17:21:05+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%BD%91%E7%BB%9C/" itemprop="url" rel="index"><span itemprop="name">网络</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>之前对网络各层作用的了解一直都比较模糊，对各个协议的作用也不甚清楚，最近看到了一篇对TCP/IP协议栈讲解比较清晰的博文，特地转载过来。</p>
<p><a target="_blank" rel="noopener" href="https://www.cnblogs.com/onepixel/p/7092302.html">原文链接</a></p>
<h2 id="什么是TCP-IP协议栈"><a href="#什么是TCP-IP协议栈" class="headerlink" title="什么是TCP/IP协议栈"></a>什么是TCP/IP协议栈</h2><p>TCP/IP 协议栈是一系列网络协议的总和，是构成网络通信的核心骨架，它定义了电子设备如何连入因特网，以及数据如何在它们之间进行传输。TCP/IP 协议采用4层结构，分别是**<font color='yellow'>应用层、传输层、网络层和链路层</font><strong>，每一层都呼叫它的下一层所提供的协议来完成自己的需求。由于我们大部分时间都工作在应用层，下层的事情不用我们操心；其次网络协议体系本身就很复杂庞大，入门门槛高，因此很难搞清楚TCP/IP的工作原理，通俗一点讲就是，</strong><font color='yellow'>一个主机的数据要经过哪些过程才能发送到对方的主机上</font>**。 </p>
<h2 id="物理介质"><a href="#物理介质" class="headerlink" title="物理介质"></a>物理介质</h2><p>物理介质就是把电脑连接起来的物理手段，常见的有光纤、双绞线，以及无线电波，它决定了电信号(0和1)的传输方式，物理介质的不同决定了电信号的传输带宽、速率、传输距离以及抗干扰性等等。</p>
<p>TCP/IP协议栈分为四层，每一层都由特定的协议与对方进行通信，而**<font color='yellow'>协议之间的通信最终都要转化为 0 和 1 的电信号，通过物理介质进行传输才能到达对方的电脑</font>**，因此物理介质是网络通信的基石。</p>
<p>下面我们通过一张图先来大概了解一下TCP/IP协议的基本框架：<br><img src="https://img-blog.csdnimg.cn/20200404205007610.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>当通过http发起一个请求时，应用层、传输层、网络层和链路层的相关协议依次对该请求进行包装并携带对应的<strong>首部</strong>，最终在链路层生成以<strong>太网数据包</strong>，以太网数据包通过物理介质传输给对方主机，对方接收到数据包以后，然后再一层一层采用对应的协议进行拆包，最后把应用层数据交给应用程序处理。</p>
<p>网络通信就好比送快递，商品外面的一层层包裹就是各种协议，协议包含了商品信息、收货地址、收件人、联系方式等，然后还需要配送车、配送站、快递员，商品才能最终到达用户手中。</p>
<p>一般情况下，快递是不能直达的，需要先转发到对应的配送站，然后由配送站再进行派件。</p>
<p>配送车就是物理介质，配送站就是网关， 快递员就是路由器，收货地址就是IP地址，联系方式就是MAC地址。 </p>
<p>快递员负责把包裹转发到各个配送站，配送站根据收获地址里的省市区，确认是否需要继续转发到其他配送站，当包裹到达了目标配送站以后，配送站再根据联系方式找到收件人进行派件。  </p>
<p>有了整体概念以后，下面我们详细了解一下各层的分工。</p>
<h2 id="链路层"><a href="#链路层" class="headerlink" title="链路层"></a>链路层</h2><p>网络通信就是把有特定意义的数据通过物理介质传送给对方，单纯的发送 0 和 1 是没有意义的，要传输有意义的数据，就需要以字节为单位对 0 和 1 进行分组，并且要标识好每一组电信号的信息特征，然后按照分组的顺序依次发送。以太网规定一组电信号就是一个数据包，一个数据包被称为**<font color='yellow'>一帧</font><strong>， 制定这个规则的协议就是</strong><font color='yellow'>以太网协议</font><strong>。一个完整的以太网数据包如下图所示：<br><img src="https://img-blog.csdnimg.cn/202004042051205.png" alt="在这里插入图片描述"><br>整个数据帧由</strong><font color='yellow'>首部、数据和尾部</font>**三部分组成，首部固定为14个字节，包含了目标MAC地址、源MAC地址和类型；数据最短为46个字节，最长为1500个字节，如果需要传输的数据很长，就必须分割成多个帧进行发送；尾部固定为4个字节，表示数据帧校验序列，用于确定数据包在传输过程中是否损坏。因此，以太网协议通过对电信号进行分组并形成数据帧，然后通过物理介质把数据帧发送给接收方。那么以太网如何来识接收方的身份呢？</p>
<p>以太网规协议定，接入网络的设备都必须安装网络适配器，即**<font color='yellow'>网卡</font><strong>， 数据包必须是从一块网卡传送到另一块网卡。而</strong><font color='yellow'>网卡地址</font><strong>就是数据包的发送地址和接收地址，也就是帧首部所包含的</strong><font color='yellow'>MAC地址</font>**，MAC地址是每块网卡的身份标识，就如同我们身份证上的身份证号码，具有全球唯一性。MAC地址采用十六进制标识，共6个字节， 前三个字节是厂商编号，后三个字节是网卡流水号，例如 4C-0F-6E-12-D2-19</p>
<p>有了MAC地址以后，以太网采用**<font color='yellow'>广播</font><strong>形式，把数据包发给该</strong><font color='yellow'>子网内</font>**所有主机，子网内每台主机在接收到这个包以后，都会读取首部里的目标MAC地址，然后和自己的MAC地址进行对比，如果相同就做下一步处理，如果不同，就丢弃这个包。</p>
<p>所以链路层的主要工作就是**<font color='yellow'>对电信号进行分组并形成具有特定意义的数据帧，然后以广播的形式通过物理介质发送给接收方。</font>**</p>
<h2 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h2><p>对于上面的过程，有几个细节问题值得我们思考：</p>
<p>1、发送者如何知道接收者的MAC地址？</p>
<p>2、发送者如何知道接收者和自己同属一个子网？</p>
<p>3、如果接收者和自己不在同一个子网，数据包如何发给对方？<br>为了解决这些问题，网络层引入了三个协议，分别是**<font color='yellow'>IP协议、ARP协议、路由协议。</font>**</p>
<h4 id="IP协议"><a href="#IP协议" class="headerlink" title="IP协议"></a>IP协议</h4><p>通过前面的介绍我们知道，MAC地址只与厂商有关，与所处的网络无关，所以无法通过MAC地址来判断两台主机是否属于同一个子网。</p>
<p>因此，网络层引入了IP协议，制定了一套新地址，使得我们能够区分两台主机是否同属一个网络，这套地址就是网络地址，也就是所谓的IP地址。</p>
<p>IP地址目前有两个版本，分别是IPv4和IPv6，IPv4是一个32位的地址，常采用4个十进制数字表示。IP协议将这个32位的地址分为两部分，前面部分代表网络地址，后面部分表示该主机在局域网中的地址。由于各类地址的分法不尽相同，以C类地址192.168.24.1为例，其中前24位就是网络地址，后8位就是主机地址。因此， **<font color='yellow'>如果两个IP地址在同一个子网内，则网络地址一定相同</font>**。为了判断IP地址中的网络地址，IP协议还引入了子网掩码， IP地址和子网掩码通过按位与运算后就可以得到网络地址。</p>
<p>由于发送者和接收者的IP地址是已知的(应用层的协议会传入)， 因此我们只要通过子网掩码对两个IP地址进行AND运算后就能够判断双方是否在同一个子网了。</p>
<h4 id="ARP协议"><a href="#ARP协议" class="headerlink" title="ARP协议"></a>ARP协议</h4><p>即地址解析协议，是**<font color='yellow'>根据IP地址获取MAC地址</font>**的一个网络层协议。其工作原理如下：</p>
<p>ARP首先会发起一个请求数据包，数据包的首部包含了目标主机的IP地址，然后这个数据包会在链路层进行再次包装，生成以太网数据包，最终由以太网广播给子网内的所有主机，每一台主机都会接收到这个数据包，并取出标头里的IP地址，然后和自己的IP地址进行比较，如果相同就返回自己的MAC地址，如果不同就丢弃该数据包。ARP接收返回消息，以此确定目标机的MAC地址；与此同时，ARP还会将返回的MAC地址与对应的IP地址存入本机ARP缓存中并保留一定时间，下次请求时直接查询ARP缓存以节约资源。cmd输入 arp -a 就可以查询本机缓存的ARP数据。</p>
<h4 id="路由协议"><a href="#路由协议" class="headerlink" title="路由协议"></a>路由协议</h4><p>通过ARP协议的工作原理可以发现，**<font color='yellow'>ARP的MAC寻址还是局限在同一个子网中</font>**，因此网络层引入了路由协议，首先通过IP协议来判断两台主机是否在同一个子网中，如果在同一个子网，就通过ARP协议查询对应的MAC地址，然后以广播的形式向该子网内的主机发送数据包；如果不在同一个子网，以太网会将该数据包转发给本子网的网关进行路由。网关是互联网上子网与子网之间的桥梁，所以网关会进行多次转发，最终将该数据包转发到目标IP所在的子网中，然后再通过ARP获取目标机MAC，最终也是通过广播形式将数据包发送给接收方。</p>
<p>而完成这个路由协议的物理设备就是**<font color='yellow'>路由器</font>**，在错综复杂的网络世界里，路由器扮演者交通枢纽的角色，它会根据信道情况，选择并设定路由，以最佳路径来转发数据包。</p>
<h4 id="IP数据包"><a href="#IP数据包" class="headerlink" title="IP数据包"></a>IP数据包</h4><p>在网络层被包装的数据包就叫**<font color='yellow'>IP数据包</font>**，IPv4数据包的结构如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200404205714539.png" alt="在这里插入图片描述"><br>IP数据包由首部和数据两部分组成，首部长度为20个字节，主要包含了目标IP地址和源IP地址，目标IP地址是网关路由的线索和依据；数据部分的最大长度为65515字节，理论上一个IP数据包的总长度可以达到65535个字节，而以太网数据包的最大长度是1500个字符，如果超过这个大小，就需要对IP数据包进行分割，分成多帧发送。</p>
<p>所以，网络层的主要工作是**<font color='yellow'>定义网络地址，区分网段，子网内MAC寻址，对于不同子网的数据包进行路由</font>**。</p>
<h4 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h4><p>链路层定义了主机的身份，即MAC地址， 而网络层定义了IP地址，明确了主机所在的网段，有了这两个地址，数据包就从可以从一个主机发送到另一台主机。但实际上数据包是从一个主机的某个应用程序发出，然后由对方主机的应用程序接收。而每台电脑都有可能同时运行着很多个应用程序，所以当数据包被发送到主机上以后，是无法确定哪个应用程序要接收这个包。</p>
<p>因此传输层引入了UDP协议来解决这个问题，为了给每个应用程序标识身份，UDP协议定义了**<font color='yellow'>端口</font>**，同一个主机上的每个应用程序都需要指定唯一的端口号，并且规定网络中传输的数据包必须加上端口信息。 这样，当数据包到达主机以后，就可以根据端口号找到对应的应用程序了。UDP定义的数据包就叫做UDP数据包，结构如下所示：<br><img src="https://img-blog.csdnimg.cn/20200404205754668.png" alt="在这里插入图片描述"><br>UDP数据包由首部和数据两部分组成，首部长度为8个字节，主要包括源端口和目标端口；数据最大为65527个字节，整个数据包的长度最大可达到65535个字节。</p>
<p>UDP协议比较简单，实现容易，但它没有确认机制， 数据包一旦发出，无法知道对方是否收到，因此可靠性较差，为了解决这个问题，提高网络可靠性，TCP协议就诞生了，TCP即传输控制协议，是一种面向连接的、可靠的、基于字节流的通信协议。简单来说TCP就是有确认机制的UDP协议，每发出一个数据包都要求确认，如果有一个数据包丢失，就收不到确认，发送方就必须重发这个数据包。<br>为了保证传输的可靠性，TCP 协议在 UDP 基础之上建立了三次对话的确认机制，也就是说，在正式收发数据前，必须和对方建立可靠的连接。由于建立过程较为复杂，我们在这里做一个形象的描述：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">主机A：我想发数据给你，可以么？</span><br><span class="line"></span><br><span class="line">主机B：可以，你什么时候发？</span><br><span class="line"></span><br><span class="line">主机A：我马上发，你接着！</span><br></pre></td></tr></table></figure>
<p>经过三次对话之后，主机A才会向主机B发送正式数据，而UDP是面向非连接的协议，它不与对方建立连接，而是直接就把数据包发过去了。所以 TCP 能够保证数据包在传输过程中不被丢失，但美好的事物必然是要付出代价的，相比 UDP，TCP 实现过程复杂，消耗连接资源多，传输速度慢。</p>
<p>TCP 数据包和 UDP 一样，都是由首部和数据两部分组成，唯一不同的是，TCP 数据包没有长度限制，理论上可以无限长，但是为了保证网络的效率，通常 TCP 数据包的长度不会超过IP数据包的长度，以确保单个 TCP 数据包不必再分割。</p>
<p>总结一下，传输层的主要工作是**<font color='yellow'>定义端口，标识应用程序身份，实现端口到端口的通信，TCP协议可以保证数据传输的可靠性</font>**。</p>
<h4 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h4><p>理论上讲，有了以上三层协议的支持，数据已经可以从一个主机上的应用程序传输到另一台主机的应用程序了，但此时传过来的数据是字节流，不能很好的被程序识别，操作性差。因此，应用层定义了各种各样的协议来规范数据格式，常见的有 HTTP、FTP、SMTP 等，HTTP 是一种比较常用的应用层协议，主要用于B/S架构之间的数据通信，其报文格式如下：<br><img src="https://img-blog.csdnimg.cn/20200404205928861.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br>在 Resquest Headers 中，Accept 表示客户端期望接收的数据格式，而 ContentType 则表示客户端发送的数据格式；在 Response Headers 中，ContentType 表示服务端响应的数据格式，这里定义的格式，一般是和  Resquest Headers 中 Accept 定义的格式是一致的。</p>
<p>有了这个规范以后，服务端收到请求以后，就能正确的解析客户端发来的数据，当请求处理完以后，再按照客户端要求的格式返回，客户端收到结果后，按照服务端返回的格式进行解析。</p>
<p>所以应用层的主要工作就是**<font color='yellow'>定义数据格式并按照对应的格式解读数据</font>**。</p>
<h4 id="全流程"><a href="#全流程" class="headerlink" title="全流程"></a>全流程</h4><p>首先我们梳理一下每层模型的职责：</p>
<ul>
<li>**<font color='yellow'>链路层</font>**：对0和1进行分组，定义数据帧，确认主机的物理地址，传输数据；</li>
<li>**<font color='yellow'>网络层</font>**：定义IP地址，确认主机所在的网络位置，并通过IP进行MAC寻址，对外网数据包进行路由转发；</li>
<li>**<font color='yellow'>传输层</font>**：定义端口，确认主机上应用程序的身份，并将数据包交给对应的应用程序；</li>
<li>**<font color='yellow'>应用层</font>**：定义数据格式，并按照对应的格式解读数据。</li>
</ul>
<p>然后再把每层模型的职责串联起来，用一句通俗易懂的话讲就是：</p>
<blockquote>
<p>当你输入一个网址并按下回车键的时候，首先，应用层协议对该请求包做了格式定义；紧接着传输层协议加上了双方的端口号，确认了双方通信的应用程序；然后网络协议加上了双方的IP地址，确认了双方的网络位置；最后链路层协议加上了双方的MAC地址，确认了双方的物理位置，同时将数据进行分组，形成数据帧，采用广播方式，通过传输介质发送给对方主机。而对于不同网段，该数据包首先会转发给网关路由器，经过多次转发后，最终被发送到目标主机。目标机接收到数据包后，采用对应的协议，对帧数据进行组装，然后再通过一层一层的协议进行解析，最终被应用层的协议解析并交给服务器处理。</p>
</blockquote>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/git-commit-%E6%97%B6%E6%8F%90%E7%A4%BAplease-tell-me-who-you-are%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/git-commit-%E6%97%B6%E6%8F%90%E7%A4%BAplease-tell-me-who-you-are%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">git commit 时提示please tell me who you are解决方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 17:15:25 / 修改时间：17:20:40" itemprop="dateCreated datePublished" datetime="2021-06-08T17:15:25+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" itemprop="url" rel="index"><span itemprop="name">常见问题</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>先是按照git的提示</p>
<p>git config –global user.email “<a href="mailto:&#x79;&#111;&#x75;&#64;&#x65;&#x78;&#x61;&#109;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;">&#x79;&#111;&#x75;&#64;&#x65;&#x78;&#x61;&#109;&#x70;&#x6c;&#x65;&#46;&#x63;&#x6f;&#109;</a>“<br>git config –global user.name “Your Name”</p>
<p>进行设置，结果发现还是报错，最后找到解决方案如下：</p>
<p>git init<br>git config user.name “Your Name”<br>git config user.email “<a href="mailto:&#121;&#111;&#x75;&#x40;&#101;&#x78;&#97;&#109;&#112;&#x6c;&#101;&#x2e;&#99;&#111;&#109;">&#121;&#111;&#x75;&#x40;&#101;&#x78;&#97;&#109;&#112;&#x6c;&#101;&#x2e;&#99;&#111;&#109;</a>“<br>git add *<br>git commit -m “commit message”</p>
<p>按如上步骤操作，最后成功commit</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/Hadoop-archive%E5%BD%92%E6%A1%A3%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Hadoop-archive%E5%BD%92%E6%A1%A3%E5%91%BD%E4%BB%A4%E7%9A%84%E4%BD%BF%E7%94%A8/" class="post-title-link" itemprop="url">Hadoop archive归档命令的使用</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 16:58:03 / 修改时间：17:01:39" itemprop="dateCreated datePublished" datetime="2021-06-08T16:58:03+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/Hadoop/" itemprop="url" rel="index"><span itemprop="name">Hadoop</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="archive-命令有什么用"><a href="#archive-命令有什么用" class="headerlink" title="archive 命令有什么用"></a>archive 命令有什么用</h2><p>archive 可以用来解决 Hadoop 中的<em><strong>小文件</strong></em>问题，当存在大量小文件时，会产生如下影响：</p>
<ol>
<li>HDFS 中，小文件过多会占用大量内存，NameNode 内存容量最终会成为限制集群扩展的瓶颈。</li>
<li>HDFS 读写小文件更加耗时，因为每次都需要从 NameNode 获取元信息，并与对应的 DataNode 建立连接。</li>
<li>小文件过多会开很多 map，一个 map 启动一个 JVM 去执行，所以这些任务的初始化，启动，执行会浪费大量的资源，严重影响性能。</li>
</ol>
<h2 id="如何使用-archive-进行归档"><a href="#如何使用-archive-进行归档" class="headerlink" title="如何使用 archive 进行归档"></a>如何使用 archive 进行归档</h2><p><img src="https://img-blog.csdnimg.cn/20200428164050783.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>其实已经用法已经很明白了，name指定名字，将路径上的内容创建到 archive 文件中。</p>
<h2 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h2><p>首先我们创建一个小文件 text.txt ，上传四份到 HDFS 上</p>
<p><img src="https://img-blog.csdnimg.cn/20200428164901114.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>用官方自带的 wordcount 跑一下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428165351971.png" alt="在这里插入图片描述"></p>
<p>很明显，4个输入，接下来执行归档命令，将 small 路径下的所有文件归档到 archiveResult 中，可以看到 archive 启动了一个 MapReduce：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428165806873.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0ppYW5nemhpcWk0NTUx,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>得到：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428170355564.png" alt="在这里插入图片描述"></p>
<p>但是进去之后会发现里面并不是我们之前的几个 text.txt 文件：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428170538921.png" alt="在这里插入图片描述"></p>
<p>使用带 har 的命令即可解决：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428170942383.png" alt="在这里插入图片描述"></p>
<p>使用归档之后的文件进行 wordcount：</p>
<p><img src="https://img-blog.csdnimg.cn/20200428171245198.png" alt="在这里插入图片描述"></p>
<p>最后仍然可以得到正确的结果，但是需要注意的是：<br><strong>使用 archive 归档后，减轻的是 HDFS 的压力，对于 MapReduce 来说，输入还是四个文件。</strong></p>
<p>如果想要控制 map 数，Hive 可以通过几个参数来实现：</p>
<ol>
<li>set mapred.max.split.size = **;（决定每个map处理的最大的文件大小）</li>
<li>set mapred.min.split.size.per.node = **;（一个节点上 split 的至少的大小，这个值决定了多个DataNode 上的文件是否需要合并）</li>
<li>set mapred.min.split.size.per.rack = **;（一个交换机下 split 的至少的大小，这个值决定了多个交换机上的文件是否需要合并）</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2021/06/08/Windows%E4%B8%8B%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83ERROR-Shell-Failed-to-locate-the-winutils-binary-in-the-hadoop-binary-path%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/logo1.jpeg">
      <meta itemprop="name" content="Master Jiang">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jiang's blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021/06/08/Windows%E4%B8%8B%E6%90%AD%E5%BB%BA%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83ERROR-Shell-Failed-to-locate-the-winutils-binary-in-the-hadoop-binary-path%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">Windows下搭建大数据开发环境ERROR Shell: Failed to locate the winutils binary in the hadoop binary path解决方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2021-06-08 16:57:14 / 修改时间：16:57:43" itemprop="dateCreated datePublished" datetime="2021-06-08T16:57:14+08:00">2021-06-08</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98/" itemprop="url" rel="index"><span itemprop="name">常见问题</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <ol>
<li><p>在 <a target="_blank" rel="noopener" href="https://github.com/steveloughran/winutils">https://github.com/steveloughran/winutils</a> 找到自己对应的 Hadoop 版本，下载解压</p>
</li>
<li><p>在用户变量中添加 HADOOP_HOME ，值为解压的路径<br><img src="https://img-blog.csdnimg.cn/20200429112633527.png" alt="在这里插入图片描述"></p>
</li>
<li><p>配置系统变量中的 Path ，添加 $HADOOP_HOME\bin</p>
</li>
<li><p>需要重启 IDEA ，即可正常运行。</p>
</li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="上一页"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="下一页"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Master Jiang</span>
</div>

    </div>
  </footer>

  
  <script src="https://cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
